{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinileodido/MVP_PucRio_AnaliseDados/blob/main/MVP_IoT_ADBP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configura√ß√µes Iniciais do Ambiente (Instala√ß√£o de Pacotes e import para uso)"
      ],
      "metadata": {
        "id": "RwewOvZAC_zR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DPhoZKSm3_Lx",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Instalar as principais bibliotecas para evitar erros de ambiente\n",
        "!pip -q install pandas\n",
        "!pip -q install matplotlib\n",
        "!pip -q install seaborn\n",
        "!pip -q install scikit-learn\n",
        "!pip -q install missingno\n",
        "!pip -q install numpy\n",
        "!pip -q install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importar as bibliotecas necess√°rias\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import *\n",
        "\n",
        "# Op√ß√£o para exibir todas as colunas do dataframe no display\n",
        "pd.set_option('display.max_columns', 50)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import missingno as msno\n",
        "\n",
        "try:\n",
        "    from IPython.display import display, Markdown, Math, Javascript, clear_output\n",
        "    use_display = True\n",
        "except ImportError:\n",
        "    use_display = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4p12Ctwj4Kuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classes para uso na apresenta√ß√£o do notebook**:\n",
        "\n",
        "*   üé®üñåÔ∏è - **''ColoredConsole''**: classe para personalizar sa√≠das na console, adicionando cores e estilos na mensagem;\n",
        "\n",
        "*   üë®‚Äçüíªüì° - **''IoTDataPreprocessor''**: classe customizada e criada exclusivamente para uso com este dataset, contendo fun√ß√µes para an√°lise de dados e pr√©-processamento;\n",
        "\n",
        "\n",
        "*   üíª üßë - ***display_dataset_characteristics***: fun√ß√£o customizada para exibi√ß√£o das caracter√≠sticas b√°sicas, bem como as descri√ß√µes dos atributos de dados do dataset escolhido; sa√≠da dos dados em *markdown* na console.\n"
      ],
      "metadata": {
        "id": "--KAPms7DN9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Classe auxiliar \"ColoredConsole\" para personalizar as sa√≠das na console, adiciona cores e estilos na mensagem\n",
        "\n",
        "class ColoredConsole:\n",
        "    \"\"\"\n",
        "    Classe para adicionar cores na sa√≠da do console usando c√≥digos ANSI\n",
        "    \"\"\"\n",
        "\n",
        "    # C√≥digos de cores para texto\n",
        "    COLORS = {\n",
        "        'black': '\\033[30m',\n",
        "        'red': '\\033[31m',\n",
        "        'green': '\\033[32m',\n",
        "        'yellow': '\\033[33m',\n",
        "        'blue': '\\033[34m',\n",
        "        'magenta': '\\033[35m',\n",
        "        'cyan': '\\033[36m',\n",
        "        'white': '\\033[37m',\n",
        "        'bright_black': '\\033[90m',\n",
        "        'bright_red': '\\033[91m',\n",
        "        'bright_green': '\\033[92m',\n",
        "        'bright_yellow': '\\033[93m',\n",
        "        'bright_blue': '\\033[94m',\n",
        "        'bright_magenta': '\\033[95m',\n",
        "        'bright_cyan': '\\033[96m',\n",
        "        'bright_white': '\\033[97m'\n",
        "    }\n",
        "\n",
        "    # C√≥digos de cores para fundo\n",
        "    BG_COLORS = {\n",
        "        'bg_black': '\\033[40m',           # Pode n√£o funcionar (transparente)\n",
        "        'bg_red': '\\033[41m',\n",
        "        'bg_green': '\\033[42m',\n",
        "        'bg_yellow': '\\033[43m',\n",
        "        'bg_blue': '\\033[44m',\n",
        "        'bg_magenta': '\\033[45m',\n",
        "        'bg_cyan': '\\033[46m',\n",
        "        'bg_white': '\\033[47m',\n",
        "        'bg_bright_black': '\\033[100m',   # Alternativa ao bg_black\n",
        "        'bg_bright_red': '\\033[101m',\n",
        "        'bg_bright_green': '\\033[102m',\n",
        "        'bg_bright_yellow': '\\033[103m',\n",
        "        'bg_bright_blue': '\\033[104m',\n",
        "        'bg_bright_magenta': '\\033[105m',\n",
        "        'bg_bright_cyan': '\\033[106m',\n",
        "        'bg_bright_white': '\\033[107m'\n",
        "    }\n",
        "\n",
        "    # Estilos de texto\n",
        "    STYLES = {\n",
        "        'bold': '\\033[1m',\n",
        "        'dim': '\\033[2m',\n",
        "        'italic': '\\033[3m',\n",
        "        'underline': '\\033[4m',\n",
        "        'blink': '\\033[5m',\n",
        "        'reverse': '\\033[7m',\n",
        "        'strikethrough': '\\033[9m'\n",
        "    }\n",
        "\n",
        "    # C√≥digo para resetar formata√ß√£o\n",
        "    RESET = '\\033[0m'\n",
        "\n",
        "    @classmethod\n",
        "    def colorize(cls, text, color=None, bg_color=None, style=None):\n",
        "        \"\"\"\n",
        "        Aplica cores e estilos ao texto\n",
        "\n",
        "        Args:\n",
        "            text (str): Texto a ser colorido\n",
        "            color (str): Cor do texto\n",
        "            bg_color (str): Cor do fundo\n",
        "            style (str): Estilo do texto\n",
        "\n",
        "        Returns:\n",
        "            str: Texto formatado com c√≥digos ANSI\n",
        "        \"\"\"\n",
        "        result = \"\"\n",
        "\n",
        "        # Adiciona estilo\n",
        "        if style and style in cls.STYLES:\n",
        "            result += cls.STYLES[style]\n",
        "\n",
        "        # Adiciona cor do texto\n",
        "        if color and color in cls.COLORS:\n",
        "            result += cls.COLORS[color]\n",
        "\n",
        "        # Adiciona cor do fundo\n",
        "        if bg_color and bg_color in cls.BG_COLORS:\n",
        "            result += cls.BG_COLORS[bg_color]\n",
        "\n",
        "        # Adiciona o texto e reset\n",
        "        result += text + cls.RESET\n",
        "\n",
        "        return result\n",
        "\n",
        "    @classmethod\n",
        "    def print_colored(cls, text, color=None, bg_color=None, style=None, end='\\n'):\n",
        "        \"\"\"\n",
        "        Imprime texto colorido no console\n",
        "\n",
        "        Args:\n",
        "            text (str): Texto a ser impresso\n",
        "            color (str): Cor do texto\n",
        "            bg_color (str): Cor do fundo\n",
        "            style (str): Estilo do texto\n",
        "            end (str): Caractere final (padr√£o: quebra de linha)\n",
        "        \"\"\"\n",
        "        colored_text = cls.colorize(text, color, bg_color, style)\n",
        "        print(colored_text, end=end)\n",
        "\n",
        "    # M√©todos de conveni√™ncia para cores comuns\n",
        "    @classmethod\n",
        "    def success(cls, text):\n",
        "        \"\"\"Imprime texto em verde (sucesso)\"\"\"\n",
        "        cls.print_colored(text, 'bright_green', style='bold')\n",
        "\n",
        "    @classmethod\n",
        "    def error(cls, text):\n",
        "        \"\"\"Imprime texto em vermelho (erro)\"\"\"\n",
        "        cls.print_colored(text, 'bright_red', style='bold')\n",
        "\n",
        "    @classmethod\n",
        "    def warning(cls, text):\n",
        "        \"\"\"Imprime texto em amarelo (aviso)\"\"\"\n",
        "        cls.print_colored(text, 'bright_yellow', style='bold')\n",
        "\n",
        "    @classmethod\n",
        "    def info(cls, text):\n",
        "        \"\"\"Imprime texto em azul (informa√ß√£o)\"\"\"\n",
        "        cls.print_colored(text, 'bright_blue', style='bold')\n",
        "\n",
        "    @classmethod\n",
        "    def debug(cls, text):\n",
        "        \"\"\"Imprime texto em cinza (debug)\"\"\"\n",
        "        cls.print_colored(text, 'bright_black')\n",
        "\n",
        "    @classmethod\n",
        "    def header(cls, text):\n",
        "        \"\"\"Imprime cabe√ßalho destacado\"\"\"\n",
        "        cls.print_colored(text, 'white', 'bg_bright_black', 'bold')\n",
        "\n",
        "    @classmethod\n",
        "    def highlight(cls, text):\n",
        "        \"\"\"Destaca texto com fundo amarelo\"\"\"\n",
        "        cls.print_colored(text, 'black', 'bg_yellow', 'bold')\n",
        "\n",
        "    @classmethod\n",
        "    def show_section_header(cls, title):\n",
        "        \"\"\"Mostra cabe√ßalho de se√ß√£o\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        if '\\n' in title:\n",
        "            string_splited = title.split('\\n')\n",
        "            for string in string_splited:\n",
        "                ColoredConsole.header(f\" {string.strip().center(60)} \")\n",
        "        else:\n",
        "            ColoredConsole.header(f\" {title.center(60)} \")\n",
        "        print(\"=\" * 60)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7AGEiPeK4RBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Classe \"IoTDataPreprocessor\" com as principais etapas de pr√©-processamento e an√°lise de dados\n",
        "\n",
        "class IoTDataPreprocessor:\n",
        "    \"\"\"\n",
        "    Classe para pr√©-processamento completo do dataset IoT Industrial\n",
        "    \"\"\"\n",
        "    import numpy as np #adicionando pois tive erro em uma fun√ß√£o que na√µ pegou da global realuzada anteriormente\n",
        "\n",
        "    def __init__(self, df, language_en=True, language_ptbr=False):\n",
        "        self.df = df.copy()\n",
        "        self.original_df = df.copy()\n",
        "        self.scalers = {}\n",
        "        self.encoders = {}\n",
        "        self.language_en = language_en\n",
        "        self.language_ptbr = language_ptbr\n",
        "\n",
        "        #Dataframe auxiliar para posterior classifica√ß√£o do tipo de m√°quin√°rio\n",
        "        self.df_machine = self._create_machine_classification_dataframe()\n",
        "\n",
        "        # Configurar idioma e aplicar transforma√ß√µes baseadas na sele√ß√£o\n",
        "        self._configure_language_settings()\n",
        "\n",
        "    ##################################################\n",
        "    ## Fun√ß√µes auxiliares para inicializa√ß√£o da Classe\n",
        "    ## 1. Cria o dataframe auxiliar para tipo de maquin√°rio\n",
        "    def _create_machine_classification_dataframe(self):\n",
        "        \"\"\"\n",
        "        Cria o dataframe auxiliar para classifica√ß√£o de tipos de m√°quinas industriais.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame com classifica√ß√£o detalhada de m√°quinas industriais\n",
        "        \"\"\"\n",
        "        machine_data = [\n",
        "            ('Laser_Cutter', 1, 'Manufacturing and Forming', 'Fabrica√ß√£o e Conforma√ß√£o', 'M√°quina de Corte a Laser',\n",
        "             'Uses a laser beam to cut or engrave materials with extreme precision.',\n",
        "             'Utiliza um feixe de laser para cortar ou gravar materiais com extrema precis√£o.'),\n",
        "            ('CNC_Lathe', 1, 'Manufacturing and Forming', 'Fabrica√ß√£o e Conforma√ß√£o', 'Torno CNC',\n",
        "             'Machine that rotates a workpiece to shape it with cutting tools.',\n",
        "             'M√°quina que rotaciona uma pe√ßa para model√°-la com ferramentas de corte.'),\n",
        "            ('Furnace', 1, 'Manufacturing and Forming', 'Fabrica√ß√£o e Conforma√ß√£o', 'Forno Industrial',\n",
        "             'High-temperature equipment for processes such as heat treatment of metals.',\n",
        "             'Equipamento de alta temperatura para processos como tratamento t√©rmico de metais.'),\n",
        "            ('Hydraulic_Press', 1, 'Manufacturing and Forming', 'Fabrica√ß√£o e Conforma√ß√£o', 'Prensa Hidr√°ulica',\n",
        "             'Machine that uses a hydraulic cylinder to generate compressive force to press or mold materials.',\n",
        "             'M√°quina que usa um cilindro hidr√°ulico para gerar for√ßa de compress√£o para prensar ou moldar.'),\n",
        "            ('Press_Brake', 1, 'Manufacturing and Forming', 'Fabrica√ß√£o e Conforma√ß√£o', 'Dobradeira / Quinadora',\n",
        "             'Machine tool used specifically for bending sheet metal.',\n",
        "             'M√°quina-ferramenta utilizada especificamente para dobrar chapas met√°licas.'),\n",
        "            ('3D_Printer', 1, 'Manufacturing and Forming', 'Fabrica√ß√£o e Conforma√ß√£o', 'Impressora 3D',\n",
        "             'Machine that builds three-dimensional objects layer by layer from a digital model.',\n",
        "             'M√°quina que constr√≥i objetos tridimensionais camada por camada a partir de um modelo digital.'),\n",
        "            ('Grinder', 1, 'Manufacturing and Forming', 'Fabrica√ß√£o e Conforma√ß√£o', 'Retificadora / Moedor',\n",
        "             'Machine that uses an abrasive wheel to remove material and provide a high-precision finish.',\n",
        "             'M√°quina que usa um rebolo abrasivo para remover material e dar acabamento de alta precis√£o.'),\n",
        "            ('CNC_Mill', 1, 'Manufacturing and Forming', 'Fabrica√ß√£o e Conforma√ß√£o', 'Fresadora CNC',\n",
        "             'Machine that uses rotating cutting tools to remove material from a workpiece.',\n",
        "             'M√°quina que usa ferramentas de corte rotativas para remover material de uma pe√ßa.'),\n",
        "            ('Injection_Molder', 1, 'Manufacturing and Forming', 'Fabrica√ß√£o e Conforma√ß√£o', 'Injetora de Pl√°stico',\n",
        "             'Machine that manufactures plastic parts by injecting molten plastic material into a mold.',\n",
        "             'M√°quina que fabrica pe√ßas pl√°sticas injetando material pl√°stico fundido em um molde.'),\n",
        "            ('Mixer', 2, 'Processing and Assembly', 'Processamento e Montagem', 'Misturador',\n",
        "             'Equipment to combine or homogenize different materials to create a final product.',\n",
        "             'Equipamento para combinar ou homogeneizar diferentes materiais para criar um produto final.'),\n",
        "            ('Pick_and_Place', 2, 'Processing and Assembly', 'Processamento e Montagem', 'M√°quina de Pegar e Colocar',\n",
        "             'Robot that picks up components and places them in another location, common in electronics assembly.',\n",
        "             'Rob√¥ que pega componentes e os posiciona em outro local, comum na montagem de eletr√¥nicos.'),\n",
        "            ('Automated_Screwdriver', 2, 'Processing and Assembly', 'Processamento e Montagem',\n",
        "             'Parafusadeira Automatizada',\n",
        "             'Robotic system that tightens screws autonomously, ensuring consistent torque.',\n",
        "             'Sistema rob√≥tico que aperta parafusos de forma aut√¥noma, garantindo torque consistente.'),\n",
        "            ('Robot_Arm', 2, 'Processing and Assembly', 'Processamento e Montagem', 'Bra√ßo Rob√≥tico',\n",
        "             'Programmable mechanical arm used for welding, painting, assembling, handling, etc.',\n",
        "             'Bra√ßo mec√¢nico program√°vel usado para soldar, pintar, montar, manusear, etc.'),\n",
        "            ('Shuttle_System', 3, 'Material Handling and Logistics', 'Manuseio e Log√≠stica', 'Sistema de Shuttle',\n",
        "             'Automated system where a motorized cart stores and retrieves boxes/pallets on shelves.',\n",
        "             'Sistema automatizado onde um carro motorizado guarda e recupera caixas/paletes em estantes.'),\n",
        "            ('AGV', 3, 'Material Handling and Logistics', 'Manuseio e Log√≠stica', 'Ve√≠culo Guiado Automatizado',\n",
        "             'Mobile robot that transports materials autonomously within a factory or warehouse.',\n",
        "             'Rob√¥ m√≥vel que transporta materiais de forma aut√¥noma dentro de uma f√°brica ou armaz√©m.'),\n",
        "            ('Conveyor_Belt', 3, 'Material Handling and Logistics', 'Manuseio e Log√≠stica',\n",
        "             'Correia Transportadora / Esteira',\n",
        "             'Continuous transport system that moves products or materials between workstations.',\n",
        "             'Sistema de transporte cont√≠nuo que move produtos ou materiais entre esta√ß√µes de trabalho.'),\n",
        "            ('Forklift_Electric', 3, 'Material Handling and Logistics', 'Manuseio e Log√≠stica', 'Empilhadeira El√©trica',\n",
        "             'Vehicle for lifting and moving heavy loads, ideal for indoor environments.',\n",
        "             'Ve√≠culo para levantar e mover cargas pesadas, ideal para ambientes internos.'),\n",
        "            ('Crane', 3, 'Material Handling and Logistics', 'Manuseio e Log√≠stica', 'Ponte Rolante / Guindaste',\n",
        "             'Used to lift and move extremely heavy loads that other machines cannot handle.',\n",
        "             'Utilizado para i√ßar e mover cargas extremamente pesadas que outras m√°quinas n√£o conseguem.'),\n",
        "            ('Vision_System', 4, 'Inspection and Quality Control', 'Inspe√ß√£o e Qualidade', 'Sistema de Vis√£o',\n",
        "             'Uses cameras and software for quality inspection, defect detection, and robot guidance.',\n",
        "             'Usa c√¢meras e software para inspe√ß√£o de qualidade, detec√ß√£o de defeitos e guiamento de rob√¥s.'),\n",
        "            ('CMM', 4, 'Inspection and Quality Control', 'Inspe√ß√£o e Qualidade', 'M√°q. de Medi√ß√£o por Coordenadas',\n",
        "             'High-precision device for measuring the geometric dimensions of an object.',\n",
        "             'Dispositivo de alta precis√£o para medir as dimens√µes geom√©tricas de um objeto.'),\n",
        "            ('XRay_Inspector', 4, 'Inspection and Quality Control', 'Inspe√ß√£o e Qualidade', 'Inspetor de Raios-X',\n",
        "             'System that uses X-rays to detect internal physical contaminants in products.',\n",
        "             'Sistema que usa raios-X para detectar contaminantes f√≠sicos dentro de produtos.'),\n",
        "            ('Labeler', 5, 'Packaging and Finishing', 'Embalagem e Finaliza√ß√£o', 'Rotuladora',\n",
        "             'Machine that applies labels or tags to products, packages, or containers.',\n",
        "             'M√°quina que aplica etiquetas ou r√≥tulos em produtos, embalagens ou recipientes.'),\n",
        "            ('Shrink_Wrapper', 5, 'Packaging and Finishing', 'Embalagem e Finaliza√ß√£o', 'Embaladora Termoencolh√≠vel',\n",
        "             'Wraps a product with plastic film and applies heat to make the film shrink and fit snugly.',\n",
        "             'Envolve um produto com filme pl√°stico e aplica calor para que o filme encolha e se ajuste.'),\n",
        "            ('Dryer', 5, 'Packaging and Finishing', 'Embalagem e Finaliza√ß√£o', 'Secador Industrial',\n",
        "             'Equipment that removes moisture from materials, usually before packaging.',\n",
        "             'Equipamento que remove umidade de materiais, geralmente antes de embalar.'),\n",
        "            ('Carton_Former', 5, 'Packaging and Finishing', 'Embalagem e Finaliza√ß√£o', 'Armadora de Caixas',\n",
        "             'Machine that automatically assembles cardboard boxes from flat blanks.',\n",
        "             'M√°quina que monta caixas de papel√£o automaticamente a partir de pe√ßas planas.'),\n",
        "            ('Vacuum_Packer', 5, 'Packaging and Finishing', 'Embalagem e Finaliza√ß√£o', 'Embaladora a V√°cuo',\n",
        "             \"Machine that removes air from a package before sealing it, extending the product's shelf life.\",\n",
        "             'M√°quina que remove o ar de uma embalagem antes de sel√°-la, estendendo a vida √∫til do produto.'),\n",
        "            ('Palletizer', 5, 'Packaging and Finishing', 'Embalagem e Finaliza√ß√£o', 'Paletizador',\n",
        "             'Machine that automatically organizes and stacks boxes or products onto a pallet.',\n",
        "             'M√°quina que organiza e empilha caixas ou produtos de forma autom√°tica sobre um palete.'),\n",
        "            ('Industrial_Chiller', 6, 'Support and Utilities', 'Suporte e Utilit√°rios', 'Chiller Industrial',\n",
        "             'Refrigeration system that removes heat from a liquid to cool equipment and processes.',\n",
        "             'Sistema de refrigera√ß√£o que remove o calor de um l√≠quido para resfriar equipamentos e processos.'),\n",
        "            ('Valve_Controller', 6, 'Support and Utilities', 'Suporte e Utilit√°rios', 'Controlador de V√°lvula',\n",
        "             'Device that manages the opening and closing of valves to regulate the flow of fluids.',\n",
        "             'Dispositivo que gerencia a abertura e o fechamento de v√°lvulas para regular o fluxo de fluidos.'),\n",
        "            ('Compressor', 6, 'Support and Utilities', 'Suporte e Utilit√°rios', 'Compressor',\n",
        "             'Generates compressed air to power pneumatic tools and actuators throughout the factory.',\n",
        "             'Gera ar comprimido para alimentar ferramentas pneum√°ticas e atuadores em toda a f√°brica.'),\n",
        "            ('Boiler', 6, 'Support and Utilities', 'Suporte e Utilit√°rios', 'Caldeira',\n",
        "             'Equipment that heats water to generate steam for heating and industrial processes.',\n",
        "             'Equipamento que aquece √°gua para gerar vapor para aquecimento e processos industriais.'),\n",
        "            ('Heat_Exchanger', 6, 'Support and Utilities', 'Suporte e Utilit√°rios', 'Trocador de Calor',\n",
        "             'Device that transfers heat between two fluids without them mixing.',\n",
        "             'Dispositivo que transfere calor entre dois fluidos sem que eles se misturem.'),\n",
        "            ('Pump', 6, 'Support and Utilities', 'Suporte e Utilit√°rios', 'Bomba',\n",
        "             'Mechanical device that moves fluids (liquids or gases) through a system.',\n",
        "             'Dispositivo mec√¢nico que move fluidos (l√≠quidos ou gases) atrav√©s de um sistema.'),\n",
        "        ]\n",
        "\n",
        "        columns = ['Machine_Type', 'ID_Group', 'Machine_Functional_Category', 'Categoria_Funcional_M√°quina',\n",
        "                   'Tipo_M√°quina', 'Explanation', 'Explica√ß√£o']\n",
        "\n",
        "        return pd.DataFrame(machine_data, columns=columns)\n",
        "\n",
        "    ## 2. Configura√ß√£o das vari√°veis baseado no idioma escolhido\n",
        "    def _configure_language_settings(self):\n",
        "        \"\"\"\n",
        "        Configura as defini√ß√µes de idioma e aplica as transforma√ß√µes necess√°rias no DataFrame.\n",
        "        Aplica renomea√ß√£o de colunas e merge com dados de classifica√ß√£o de m√°quinas baseado no idioma selecionado.\n",
        "        \"\"\"\n",
        "        if self.language_ptbr:\n",
        "            self._apply_portuguese_configuration()\n",
        "        elif self.language_en:\n",
        "            self._apply_english_configuration()\n",
        "\n",
        "    ## 3. Configura as vari√°veis no idioma Portug√™s (PtBr)\n",
        "    def _apply_portuguese_configuration(self):\n",
        "        \"\"\"\n",
        "        Aplica configura√ß√µes espec√≠ficas para o idioma portugu√™s.\n",
        "        Renomeia colunas para portugu√™s e faz merge com classifica√ß√£o de m√°quinas em portugu√™s.\n",
        "        \"\"\"\n",
        "        portuguese_columns = [\n",
        "            'ID_M√°quina',\n",
        "            'Tipo_M√°quina',\n",
        "            'Ano_Instala√ß√£o',\n",
        "            'Horas_Opera√ß√£o',\n",
        "            'Temperatura_Celsius',\n",
        "            'Vibra√ß√£o_mms',\n",
        "            'Ru√≠do_dB',\n",
        "            'N√≠vel_√ìleo_%',\n",
        "            'Fluido_Refrigerante_%',\n",
        "            'Consumo_Energia_kW',\n",
        "            'Dias_Ultima_Manuten√ß√£o',\n",
        "            'Hist√≥rico_Manuten√ß√µes',\n",
        "            'Hist√≥rico_Falhas',\n",
        "            'Supervis√£o_IA',\n",
        "            'C√≥digos_Erros_30_Dias',\n",
        "            'Vida_√ötil_Restante_Dias',\n",
        "            'Falha_Nos_Pr√≥ximos_7_Dias',\n",
        "            'Intensidade_Laser',\n",
        "            'Press√£o_Hidr√°ulica_bar',\n",
        "            'Fluxo_Fluido_Refrigerante_L_min',\n",
        "            '√çndice_Calor',\n",
        "            'Eventos_Sobrescrita_IA'\n",
        "        ]\n",
        "\n",
        "        # Renomear colunas para portugu√™s\n",
        "        self.df.columns = portuguese_columns\n",
        "\n",
        "        # Preparar subset para merge em portugu√™s\n",
        "        df_subset = self.df_machine[['Machine_Type', 'Tipo_M√°quina', 'Categoria_Funcional_M√°quina']].copy()\n",
        "        df_subset.columns = ['Machine_Type', 'Tipo_M√°quina_ptbr', 'Categoria_Funcional_M√°quina']\n",
        "\n",
        "        # Fazer merge e limpar colunas auxiliares\n",
        "        self.df = pd.merge(self.df, df_subset, left_on='Tipo_M√°quina', right_on='Machine_Type', how='inner')\n",
        "        self.df['Tipo_M√°quina'] = self.df['Tipo_M√°quina_ptbr']\n",
        "        self.df = self.df.drop(columns=['Machine_Type', 'Tipo_M√°quina_ptbr'], axis=1)\n",
        "\n",
        "    ## 4. Configura as vari√°veis no idioma Ingl√™s (English)\n",
        "    def _apply_english_configuration(self):\n",
        "        \"\"\"\n",
        "        Aplica configura√ß√µes espec√≠ficas para o idioma ingl√™s.\n",
        "        Faz merge com classifica√ß√£o de m√°quinas em ingl√™s mantendo nomes originais das colunas.\n",
        "        \"\"\"\n",
        "        # Fazer merge com dados de classifica√ß√£o em ingl√™s\n",
        "        self.df = pd.merge(self.df, self.df_machine[['Machine_Type', 'Machine_Functional_Category']],\n",
        "                           left_on='Machine_Type', right_on='Machine_Type', how='inner')\n",
        "\n",
        "\n",
        "    ##################################################\n",
        "    ## Fun√ß√µes de an√°lises e pr√©-processamento de dados\n",
        "\n",
        "    ## 1. An√°lise do dataset\n",
        "    def analyze_data_quality(self, show_output=True, show_missingno=True):\n",
        "        \"\"\"\n",
        "        1. AN√ÅLISE DE QUALIDADE DOS DADOS\n",
        "\n",
        "        Parameters:\n",
        "        - show_output: bool, se deve exibir informa√ß√µes textuais\n",
        "        - show_missingno: bool, se deve exibir visualiza√ß√µes do missingno\n",
        "        \"\"\"\n",
        "        if show_output:\n",
        "            display(Markdown(\"---\"))\n",
        "            display(Markdown(\"### **An√°lise dos dados e Informa√ß√µes b√°sicas do dataset**\"))\n",
        "            ColoredConsole.show_section_header(\"AN√ÅLISE DE QUALIDADE DOS DADOS\")\n",
        "\n",
        "        # Informa√ß√µes b√°sicas\n",
        "        if show_output:\n",
        "            print('\\n')\n",
        "            ColoredConsole.debug(\"*******************************\")\n",
        "            ColoredConsole.info(f\"Shape do dataset: {self.df.shape}\")\n",
        "            print('\\n')\n",
        "            ColoredConsole.debug(\"*******************************\")\n",
        "            ColoredConsole.info(\"Informa√ß√µes do dataset:\")\n",
        "            self.df.info()\n",
        "            print('\\n')\n",
        "\n",
        "            ColoredConsole.debug(\"*******************************\")\n",
        "            ColoredConsole.info(\"Tipos de dados:\")\n",
        "            print(self.df.dtypes.value_counts().to_frame('Contagem'))\n",
        "            print('\\n')\n",
        "\n",
        "            ColoredConsole.debug(\"*******************************\")\n",
        "            ColoredConsole.info(\"Primeiras linhas do dataset:\")\n",
        "            if use_display:\n",
        "                display(self.df.head())\n",
        "                print('\\n')\n",
        "            else:\n",
        "                print(self.df.head())\n",
        "\n",
        "            ColoredConsole.debug(\"*******************************\")\n",
        "            ColoredConsole.info(\"√öltimas linhas do dataset:\")\n",
        "            if use_display:\n",
        "                display(self.df.tail())\n",
        "                print('\\n')\n",
        "            else:\n",
        "                print(self.df.tail())\n",
        "\n",
        "            display(Markdown(\"### **Estat√≠sticas descritivas do dataset**\"))\n",
        "            ColoredConsole.debug(\"*******************************\")\n",
        "            ColoredConsole.info(\"Resumo estat√≠stico do dataset:\")\n",
        "            if use_display:\n",
        "                display(self.df.describe())\n",
        "                print('\\n')\n",
        "            else:\n",
        "                print(self.df.describe())\n",
        "\n",
        "        # Valores missing\n",
        "        if show_output:\n",
        "            print('\\n')\n",
        "            display(Markdown(\"---\"))\n",
        "            display(Markdown(\"### **Valores faltantes** (*Missing*)\"))\n",
        "\n",
        "        missing_data = self.df.isnull().sum()\n",
        "        missing_pct = (missing_data / len(self.df)) * 100\n",
        "\n",
        "        if missing_data.sum() > 0:\n",
        "            if show_output:\n",
        "                ColoredConsole.debug(\"*******************************\")\n",
        "                ColoredConsole.info(\"Valores missing:\")\n",
        "            for col, count in missing_data[missing_data > 0].items():\n",
        "                if show_output:\n",
        "                    ColoredConsole.debug(f\"  {col}: {count} ({missing_pct[col]:.2f}%)\")\n",
        "\n",
        "        # Duplicatas\n",
        "        duplicates = self.df.duplicated().sum()\n",
        "        if show_output:\n",
        "            print('\\n')\n",
        "            display(Markdown(\"---\"))\n",
        "            display(Markdown(\"### **Dados duplicados**\"))\n",
        "            ColoredConsole.debug(\"*******************************\")\n",
        "            ColoredConsole.info(f\"Registros duplicados: {duplicates}\")\n",
        "\n",
        "        # Distribui√ß√£o da vari√°vel target\n",
        "        if self.language_en:\n",
        "            target_col = 'Failure_Within_7_Days'\n",
        "        elif self.language_ptbr:\n",
        "            target_col = 'Falha_Nos_Pr√≥ximos_7_Dias'\n",
        "\n",
        "        if target_col in self.df.columns:\n",
        "            target_dist = self.df[target_col].value_counts(normalize=True)\n",
        "            if show_output:\n",
        "                print('\\n')\n",
        "                display(Markdown(\"---\"))\n",
        "                display(Markdown(\"### **Distribui√ß√£o Vari√°vel Target**\"))\n",
        "                ColoredConsole.debug(\"*******************************\")\n",
        "                target_prefix_info_text = ColoredConsole.colorize(\"Distribui√ß√£o da vari√°vel target (\\\"\", 'blue', None)\n",
        "                target_suffix_info_text = ColoredConsole.colorize(\"\\\")\", 'blue', None)\n",
        "                tarteg_col_colored = ColoredConsole.colorize(target_col, 'red', style='bold')\n",
        "                print(target_prefix_info_text + tarteg_col_colored + target_suffix_info_text)\n",
        "                #ColoredConsole.info(f\"Distribui√ß√£o da vari√°vel target ({target_col}):\")\n",
        "                ColoredConsole.info(f\"  \\\"N√£o falha\\\" (0): {target_dist[0]:.2%}\")\n",
        "                ColoredConsole.info(f\"  \\\"Falha\\\" (1): {target_dist[1]:.2%}\")\n",
        "\n",
        "        return missing_data, duplicates\n",
        "\n",
        "    ## 2. Tratamento de valores faltantes\n",
        "    def handle_missing_values(self, strategy='mean', show_output=True, show_missingno=True, return_df=True):\n",
        "        \"\"\"\n",
        "        2. TRATAMENTO DE VALORES MISSING com visualiza√ß√£o antes/depois\n",
        "        \"\"\"\n",
        "        # Limpar outputs anteriores para evitar ac√∫mulo\n",
        "        if show_output:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "        if show_output:\n",
        "            ColoredConsole.show_section_header(\"TRATAMENTO DE VALORES MISSING\")\n",
        "\n",
        "        missing_data, _ = self.analyze_data_quality(show_output=False, show_missingno=False)\n",
        "\n",
        "        if missing_data.sum() == 0:\n",
        "            if show_output:\n",
        "                ColoredConsole.success(\"‚úì N√£o h√° valores missing para tratar\")\n",
        "            if show_missingno and show_output:\n",
        "                # Mostrar matriz mesmo sem missing para confirmar limpeza\n",
        "                try:\n",
        "                    fig, ax = plt.subplots(figsize=(16, 8))\n",
        "                    msno.matrix(self.df, ax=ax)\n",
        "                    ax.set_title('Confirma√ß√£o: Dataset Sem Dados Faltantes', fontsize=14, fontweight='bold', pad=20)\n",
        "                    ax.xaxis.tick_bottom()\n",
        "                    ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
        "                    plt.setp(ax.get_xticklabels(), ha='right')\n",
        "                    plt.subplots_adjust(bottom=0.2)\n",
        "                    plt.tight_layout()\n",
        "                    plt.show()\n",
        "                    ColoredConsole.success(\"‚úì Visualiza√ß√£o confirmada: Sem dados faltantes\")\n",
        "                except Exception as e:\n",
        "                    ColoredConsole.warning(f\"‚ö† Erro na visualiza√ß√£o: {str(e)}\")\n",
        "            return self.df\n",
        "\n",
        "        # ANTES DO TRATAMENTO\n",
        "        if show_missingno and show_output:\n",
        "            try:\n",
        "                ColoredConsole.info(\"DADOS FALTANTES - ANTES DO TRATAMENTO:\")\n",
        "\n",
        "                # Criar subplot com 2 gr√°ficos lado a lado\n",
        "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "                # Gr√°fico 1: Matriz ANTES do tratamento\n",
        "                msno.matrix(self.df, ax=ax1)\n",
        "                ax1.set_title('ANTES: Dados Faltantes', fontsize=14, fontweight='bold', pad=20)\n",
        "                ax1.xaxis.tick_bottom()\n",
        "                ax1.tick_params(axis='x', rotation=45, labelsize=9)\n",
        "                plt.setp(ax1.get_xticklabels(), ha='right')\n",
        "\n",
        "                # Placeholder para o segundo gr√°fico (ser√° preenchido depois)\n",
        "                ax2.text(0.5, 0.5, 'Processando tratamento...',\n",
        "                        horizontalalignment='center', verticalalignment='center',\n",
        "                        transform=ax2.transAxes, fontsize=12)\n",
        "                ax2.set_title('DEPOIS: Dados Tratados', fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "            except Exception as e:\n",
        "                ColoredConsole.warning(f\"‚ö† Erro na visualiza√ß√£o inicial: {str(e)}\")\n",
        "\n",
        "        # APLICAR TRATAMENTO DOS MISSING VALUES\n",
        "        if show_output:\n",
        "            ColoredConsole.info(f\"Aplicando estrat√©gia: {strategy}\")\n",
        "\n",
        "        # Separar colunas por tipo\n",
        "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
        "        categorical_cols = self.df.select_dtypes(include=['object']).columns\n",
        "\n",
        "        # Tratar num√©ricos\n",
        "        for col in numeric_cols:\n",
        "            if self.df[col].isnull().sum() > 0:\n",
        "                if strategy == 'mean':\n",
        "                    fill_value = self.df[col].mean()\n",
        "                elif strategy == 'median':\n",
        "                    fill_value = self.df[col].median()\n",
        "                elif strategy == 'zero':\n",
        "                    fill_value = 0\n",
        "                elif strategy == 'forward_fill':\n",
        "                    self.df[col] = self.df[col].ffill()\n",
        "                    continue\n",
        "\n",
        "                self.df[col] = self.df[col].fillna(fill_value)\n",
        "                if show_output:\n",
        "                    if strategy == 'zero':\n",
        "                        ColoredConsole.debug(f\"  {col}: preenchido com zero\")\n",
        "                    else:\n",
        "                        ColoredConsole.debug(f\"  {col}: preenchido com {strategy} = {fill_value:.2f}\")\n",
        "\n",
        "        # Tratar categ√≥ricos\n",
        "        for col in categorical_cols:\n",
        "            if self.df[col].isnull().sum() > 0:\n",
        "                if strategy == 'zero':\n",
        "                    fill_value = ''\n",
        "                    self.df[col] = self.df[col].fillna(fill_value)\n",
        "                    if show_output:\n",
        "                        ColoredConsole.debug(f\"  {col}: preenchido com string vazia\")\n",
        "                else:\n",
        "                    mode_value = self.df[col].mode()[0]\n",
        "                    self.df[col] = self.df[col].fillna(mode_value)\n",
        "                    if show_output:\n",
        "                        ColoredConsole.debug(f\"  {col}: preenchido com moda = {mode_value}\")\n",
        "\n",
        "        # DEPOIS DO TRATAMENTO\n",
        "        if show_missingno and show_output:\n",
        "            try:\n",
        "                ColoredConsole.info(\"RESULTADO FINAL - ANTES vs DEPOIS:\")\n",
        "\n",
        "                # Criar figura com antes e depois\n",
        "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "                # Recriar dados originais com missing para compara√ß√£o\n",
        "                df_original_missing = self.original_df.copy()\n",
        "\n",
        "                # Gr√°fico 1: ANTES (dados originais com missing)\n",
        "                msno.matrix(df_original_missing, ax=ax1)\n",
        "                ax1.set_title('ANTES: Dados Faltantes', fontsize=14, fontweight='bold', pad=20, color='red')\n",
        "                ax1.xaxis.tick_bottom()\n",
        "                ax1.tick_params(axis='x', rotation=45, labelsize=9)\n",
        "                plt.setp(ax1.get_xticklabels(), ha='right')\n",
        "\n",
        "                # Gr√°fico 2: DEPOIS (dados tratados)\n",
        "                msno.matrix(self.df, ax=ax2)\n",
        "                ax2.set_title('DEPOIS: Dados Tratados', fontsize=14, fontweight='bold', pad=20, color='green')\n",
        "                ax2.xaxis.tick_bottom()\n",
        "                ax2.tick_params(axis='x', rotation=45, labelsize=9)\n",
        "                plt.setp(ax2.get_xticklabels(), ha='right')\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "                # Mostrar estat√≠sticas de compara√ß√£o\n",
        "                missing_before = df_original_missing.isnull().sum().sum()\n",
        "                missing_after = self.df.isnull().sum().sum()\n",
        "\n",
        "                ColoredConsole.success(f\"‚úì Tratamento conclu√≠do:\")\n",
        "                ColoredConsole.info(f\"  ‚Ä¢ Missing values ANTES: {missing_before}\")\n",
        "                ColoredConsole.info(f\"  ‚Ä¢ Missing values DEPOIS: {missing_after}\")\n",
        "                ColoredConsole.info(f\"  ‚Ä¢ Valores preenchidos: {missing_before - missing_after}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                ColoredConsole.warning(f\"‚ö† Erro na visualiza√ß√£o final: {str(e)}\")\n",
        "\n",
        "        if return_df:\n",
        "            return self.df\n",
        "\n",
        "    ## 3. Detec√ß√£o e tratamento de outliers\n",
        "    def detect_outliers(self, method='iqr', threshold=1.5):\n",
        "        \"\"\"\n",
        "        3.a) Detectar outliers usando IQR ou Z-score\n",
        "        \"\"\"\n",
        "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
        "        outliers_info = {}\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            if method == 'iqr':\n",
        "                Q1 = self.df[col].quantile(0.25)\n",
        "                Q3 = self.df[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower_bound = Q1 - threshold * IQR\n",
        "                upper_bound = Q3 + threshold * IQR\n",
        "                outliers = self.df[(self.df[col] < lower_bound) | (self.df[col] > upper_bound)]\n",
        "\n",
        "            elif method == 'zscore':\n",
        "                z_scores = np.abs((self.df[col] - self.df[col].mean()) / self.df[col].std())\n",
        "                outliers = self.df[z_scores > threshold]\n",
        "\n",
        "            outliers_info[col] = {\n",
        "                'count': len(outliers),\n",
        "                'percentage': len(outliers) / len(self.df) * 100,\n",
        "                'indices': outliers.index.tolist()\n",
        "            }\n",
        "\n",
        "        return outliers_info\n",
        "\n",
        "    def handle_outliers(self, method='cap', outlier_info=None, show_output=True):\n",
        "        \"\"\"\n",
        "        3.b) Tratar outliers (cap, remove, transform) com sa√≠das no console\n",
        "        \"\"\"\n",
        "        if show_output:\n",
        "            ColoredConsole.show_section_header(\"TRATAMENTO DE OUTLIERS\")\n",
        "\n",
        "        # Se n√£o foram fornecidas informa√ß√µes de outliers, detecta automaticamente\n",
        "        if outlier_info is None:\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"üîç Detectando outliers automaticamente...\")\n",
        "            outlier_info = self.detect_outliers()\n",
        "\n",
        "        # Informa o m√©todo que ser√° utilizado\n",
        "        method_names = {\n",
        "            'cap': 'Capping/Winsorization',\n",
        "            'remove': 'Remo√ß√£o de linhas',\n",
        "            'log_transform': 'Transforma√ß√£o Logar√≠tmica'\n",
        "        }\n",
        "\n",
        "        if show_output:\n",
        "            ColoredConsole.info(f\"üìä M√©todo selecionado: {method_names.get(method, method)}\")\n",
        "\n",
        "        # Contadores para estat√≠sticas\n",
        "        total_outliers_found = sum(info['count'] for info in outlier_info.values())\n",
        "        columns_with_outliers = sum(1 for info in outlier_info.values() if info['count'] > 0)\n",
        "\n",
        "        if total_outliers_found == 0:\n",
        "            if show_output:\n",
        "                ColoredConsole.success(\"‚úì Nenhum outlier encontrado no dataset!\")\n",
        "            return self.df\n",
        "\n",
        "        if show_output:\n",
        "            #ColoredConsole.warning(f\"‚ö†Ô∏è  Total de outliers encontrados: {total_outliers_found} em {columns_with_outliers} colunas\")\n",
        "            ColoredConsole.print_colored(f\"‚ö†Ô∏è  Total de outliers encontrados: {total_outliers_found} em {columns_with_outliers} colunas\",color='white', bg_color='bg_bright_blue',style='bold')\n",
        "        # Processa cada coluna com outliers\n",
        "        rows_before = len(self.df)\n",
        "\n",
        "        for col, info in outlier_info.items():\n",
        "            if info['count'] > 0:\n",
        "                if show_output:\n",
        "                    ColoredConsole.print_colored(f\"  ‚Ä¢ {col}: {info['count']} outliers ({info['percentage']:.1f}%)\", 'cyan')\n",
        "\n",
        "                if method == 'cap':\n",
        "                    # Winsorization - limitar aos percentis 5% e 95%\n",
        "                    lower_cap = self.df[col].quantile(0.05)\n",
        "                    upper_cap = self.df[col].quantile(0.95)\n",
        "                    self.df[col] = self.df[col].clip(lower=lower_cap, upper=upper_cap)\n",
        "\n",
        "                    if show_output:\n",
        "                        ColoredConsole.success(f\"    ‚úì Capping aplicado (P5: {lower_cap:.2f}, P95: {upper_cap:.2f})\")\n",
        "\n",
        "                elif method == 'remove':\n",
        "                    # Remove as linhas com outliers\n",
        "                    self.df = self.df.drop(info['indices'])\n",
        "\n",
        "                    if show_output:\n",
        "                        ColoredConsole.success(f\"    ‚úì {len(info['indices'])} linhas removidas\")\n",
        "\n",
        "                elif method == 'log_transform':\n",
        "                    # Verifica valores n√£o-positivos e aplica transforma√ß√£o log\n",
        "                    min_value = self.df[col].min()\n",
        "                    if min_value <= 0:\n",
        "                        if show_output:\n",
        "                            #ColoredConsole.warning(f\"    ‚ö†Ô∏è  Ajustando valores n√£o-positivos (min: {min_value:.2f})\")\n",
        "                            ColoredConsole.print_colored(f\"    ‚ö†Ô∏è  Ajustando valores n√£o-positivos (min: {min_value:.2f})\",color='white', bg_color='bg_bright_blue',style='bold')\n",
        "\n",
        "                    self.df[col] = np.log1p(self.df[col] - self.df[col].min() + 1)\n",
        "\n",
        "                    if show_output:\n",
        "                        ColoredConsole.success(f\"    ‚úì Transforma√ß√£o log1p aplicada\")\n",
        "\n",
        "        # Resumo final\n",
        "        rows_after = len(self.df)\n",
        "\n",
        "        if show_output:\n",
        "            print()\n",
        "            ColoredConsole.success(f\"‚úì Tratamento conclu√≠do:\")\n",
        "            ColoredConsole.info(f\"  ‚Ä¢ Colunas processadas: {columns_with_outliers}\")\n",
        "            ColoredConsole.info(f\"  ‚Ä¢ Total de outliers tratados: {total_outliers_found}\")\n",
        "\n",
        "            if method == 'remove' and rows_before != rows_after:\n",
        "                ColoredConsole.info(f\"  ‚Ä¢ Linhas removidas: {rows_before - rows_after}\")\n",
        "                ColoredConsole.info(f\"  ‚Ä¢ Tamanho final do dataset: {rows_after} linhas\")\n",
        "\n",
        "            if method != 'remove':\n",
        "                ColoredConsole.highlight(\"üí° Recomenda√ß√£o: Execute nova detec√ß√£o para validar o tratamento\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "\n",
        "    def validate_outlier_treatment(self, original_outlier_info=None, show_output=True, show_plot=True):\n",
        "        \"\"\"\n",
        "        3.c) Fun√ß√£o auxiliar para validar se o tratamento de outliers foi efetivo\n",
        "        \"\"\"\n",
        "        if show_output:\n",
        "            ColoredConsole.show_section_header(\"VALIDA√á√ÉO DO TRATAMENTO\")\n",
        "\n",
        "        # Detecta outliers ap√≥s o tratamento\n",
        "        #numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
        "        numeric_cols = self.df.select_dtypes(include=['number']).columns\n",
        "        new_outlier_info = {}\n",
        "\n",
        "        for col in numeric_cols:\n",
        "            Q1 = self.df[col].quantile(0.25)\n",
        "            Q3 = self.df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            outlier_count = ((self.df[col] < lower_bound) | (self.df[col] > upper_bound)).sum()\n",
        "\n",
        "            new_outlier_info[col] = {\n",
        "                'count': outlier_count,\n",
        "                'percentage': outlier_count / len(self.df) * 100\n",
        "            }\n",
        "\n",
        "        total_remaining = sum(info['count'] for info in new_outlier_info.values())\n",
        "\n",
        "        # Criar visualiza√ß√£o gr√°fica da valida√ß√£o\n",
        "        if show_plot and original_outlier_info:\n",
        "            import matplotlib.pyplot as plt\n",
        "            import numpy as np\n",
        "\n",
        "            # Preparar dados para o gr√°fico\n",
        "            columns_with_outliers = []\n",
        "            before_counts = []\n",
        "            after_counts = []\n",
        "\n",
        "            for col in original_outlier_info.keys():\n",
        "                original_count = original_outlier_info[col]['count']\n",
        "                new_count = new_outlier_info.get(col, {}).get('count', 0)\n",
        "\n",
        "                if original_count > 0:  # S√≥ incluir colunas que tinham outliers\n",
        "                    columns_with_outliers.append(col)\n",
        "                    before_counts.append(original_count)\n",
        "                    after_counts.append(new_count)\n",
        "\n",
        "            if columns_with_outliers:\n",
        "                # Criar gr√°fico de barras comparativo\n",
        "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "                # Gr√°fico 1: Antes vs Depois\n",
        "                x = np.arange(len(columns_with_outliers))\n",
        "                width = 0.35\n",
        "\n",
        "                bars1 = ax1.bar(x - width/2, before_counts, width, label='Antes', color='red', alpha=0.7)\n",
        "                bars2 = ax1.bar(x + width/2, after_counts, width, label='Depois', color='green', alpha=0.7)\n",
        "\n",
        "                ax1.set_xlabel('Vari√°veis')\n",
        "                ax1.set_ylabel('Quantidade de Outliers')\n",
        "                ax1.set_title('Compara√ß√£o: Outliers Antes vs Depois do Tratamento')\n",
        "                ax1.set_xticks(x)\n",
        "                ax1.set_xticklabels(columns_with_outliers, rotation=45, ha='right')\n",
        "                ax1.legend()\n",
        "                ax1.grid(True, alpha=0.3)\n",
        "\n",
        "                # Adicionar valores nas barras\n",
        "                for bar in bars1:\n",
        "                    height = bar.get_height()\n",
        "                    if height > 0:\n",
        "                        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                                f'{int(height)}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "                for bar in bars2:\n",
        "                    height = bar.get_height()\n",
        "                    if height > 0:\n",
        "                        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                                f'{int(height)}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "                # Gr√°fico 2: Status final (vari√°veis com outliers restantes)\n",
        "                remaining_cols = [col for col, count in zip(columns_with_outliers, after_counts) if count > 0]\n",
        "                remaining_counts = [count for count in after_counts if count > 0]\n",
        "\n",
        "                if remaining_cols:\n",
        "                    colors = ['orange' if count > 1000 else 'yellow' for count in remaining_counts]\n",
        "                    bars3 = ax2.bar(remaining_cols, remaining_counts, color=colors, alpha=0.7)\n",
        "                    ax2.set_xlabel('Vari√°veis com Outliers Restantes')\n",
        "                    ax2.set_ylabel('Quantidade de Outliers')\n",
        "                    ax2.set_title('Vari√°veis que Ainda Possuem Outliers')\n",
        "                    ax2.tick_params(axis='x', rotation=45)\n",
        "                    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "                    # Adicionar valores nas barras\n",
        "                    for bar in bars3:\n",
        "                        height = bar.get_height()\n",
        "                        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                                f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
        "                else:\n",
        "                    ax2.text(0.5, 0.5, 'üéâ Nenhuma vari√°vel\\ncom outliers restantes!',\n",
        "                            transform=ax2.transAxes, ha='center', va='center',\n",
        "                            fontsize=16, color='green', fontweight='bold')\n",
        "                    ax2.set_title('Status Final: Sem Outliers!')\n",
        "\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "        # Resumo textual conciso\n",
        "        if show_output:\n",
        "            if original_outlier_info:\n",
        "                treated_columns = sum(1 for col in original_outlier_info.keys()\n",
        "                                    if original_outlier_info[col]['count'] > 0)\n",
        "                successful_columns = sum(1 for col in original_outlier_info.keys()\n",
        "                                      if original_outlier_info[col]['count'] > 0 and\n",
        "                                      new_outlier_info.get(col, {}).get('count', 0) == 0)\n",
        "\n",
        "                ColoredConsole.info(f\"üìä Resumo da valida√ß√£o:\")\n",
        "                ColoredConsole.info(f\"  ‚Ä¢ Colunas tratadas: {treated_columns}\")\n",
        "                ColoredConsole.info(f\"  ‚Ä¢ Colunas completamente limpas: {successful_columns}\")\n",
        "                ColoredConsole.info(f\"  ‚Ä¢ Colunas com outliers restantes: {treated_columns - successful_columns}\")\n",
        "\n",
        "            if total_remaining == 0:\n",
        "                ColoredConsole.success(\"üéâ Perfeito! Nenhum outlier detectado ap√≥s tratamento\")\n",
        "            else:\n",
        "                #ColoredConsole.warning(f\"‚ö†Ô∏è  Ainda restam {total_remaining} outliers no dataset\")\n",
        "                ColoredConsole.print_colored(f\"‚ö†Ô∏è  Ainda restam {total_remaining} outliers no dataset\",color='white', bg_color='bg_bright_blue',style='bold')\n",
        "                ColoredConsole.info(\"üí° Considere ajustar threshold ou usar outro m√©todo\")\n",
        "\n",
        "        # Retornar apenas contagens, sem √≠ndices\n",
        "        return {col: {'count': info['count'], 'percentage': info['percentage']}\n",
        "                for col, info in new_outlier_info.items()}\n",
        "\n",
        "    ## 4. Engenharia de Atributos\n",
        "    def feature_engineering(self, show_output=True, return_df=True):\n",
        "        \"\"\"\n",
        "        3. ENGENHARIA DE FEATURES\n",
        "        \"\"\"\n",
        "        if show_output:\n",
        "            ColoredConsole.show_section_header(\"ENGENHARIA DE FEATURES\")\n",
        "\n",
        "        # Obter ano atual\n",
        "        now = datetime.now()\n",
        "        current_year = now.year\n",
        "\n",
        "        # ===== FILTRO DE DADOS FUTUROS =====\n",
        "        # Verificar e filtrar dados com anos de instala√ß√£o futuros (dados sint√©ticos inconsistentes)\n",
        "        if self.language_en:\n",
        "            installation_col = 'Installation_Year'\n",
        "        elif self.language_ptbr:\n",
        "            installation_col = 'Ano_Instala√ß√£o'\n",
        "\n",
        "        # Contar registros com anos futuros antes do filtro\n",
        "        future_data_count = (self.df[installation_col] > current_year).sum()\n",
        "\n",
        "        if future_data_count > 0:\n",
        "            if show_output:\n",
        "                ColoredConsole.highlight(f\"‚ö†  Encontrados {future_data_count} registros com anos de instala√ß√£o futuros (>{current_year})\")\n",
        "                ColoredConsole.info(f\"   Filtrando dados para manter apenas anos <= {current_year}\")\n",
        "\n",
        "            # Filtrar dados mantendo apenas anos <= current_year\n",
        "            self.df = self.df[self.df[installation_col] <= current_year].copy()\n",
        "\n",
        "            if show_output:\n",
        "                ColoredConsole.success(f\"‚úì Filtro aplicado: {len(self.df)} registros restantes ap√≥s remo√ß√£o de dados futuros\")\n",
        "        else:\n",
        "            if show_output:\n",
        "                ColoredConsole.success(f\"‚úì Verifica√ß√£o conclu√≠da: Nenhum dado futuro encontrado (todos os anos <= {current_year})\")\n",
        "\n",
        "        # Criar features derivadas baseadas no conhecimento do dom√≠nio\n",
        "\n",
        "        # 1. √çndice de Degrada√ß√£o Geral\n",
        "        if self.language_en:\n",
        "            self.df['Degradation_Index'] = (\n",
        "                    self.df['Temperature_C'] * 0.3 +\n",
        "                    self.df['Vibration_mms'] * 0.3 +\n",
        "                    self.df['Sound_dB'] * 0.2 +\n",
        "                    (100 - self.df['Oil_Level_pct']) * 0.1 +\n",
        "                    (100 - self.df['Coolant_Level_pct']) * 0.1\n",
        "            )\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Degradation_Index (√≠ndice composto de degrada√ß√£o)\")\n",
        "        elif self.language_ptbr:\n",
        "            self.df['√çndice_Degrada√ß√£o'] = (\n",
        "                    self.df['Temperatura_Celsius'] * 0.3 +\n",
        "                    self.df['Vibra√ß√£o_mms'] * 0.3 +\n",
        "                    self.df['Ru√≠do_dB'] * 0.2 +\n",
        "                    (100 - self.df['N√≠vel_√ìleo_%']) * 0.1 +\n",
        "                    (100 - self.df['Fluido_Refrigerante_%']) * 0.1\n",
        "            )\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: √çndice_Degrada√ß√£o (√≠ndice composto de degrada√ß√£o)\")\n",
        "\n",
        "        # 2. Idade da m√°quina (agora usando dados j√° filtrados)\n",
        "        if self.language_en:\n",
        "            self.df['Machine_Age'] = current_year - self.df['Installation_Year']\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Machine_Age (idade da m√°quina)\")\n",
        "        elif self.language_ptbr:\n",
        "            self.df['Idade_M√°quina'] = current_year - self.df['Ano_Instala√ß√£o']\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Idade_M√°quina (idade da m√°quina)\")\n",
        "\n",
        "        # 3. Intensidade de uso\n",
        "        if self.language_en:\n",
        "            self.df['Usage_Intensity'] = self.df['Operational_Hours'] / self.df['Machine_Age']\n",
        "            self.df['Usage_Intensity'] = self.df['Usage_Intensity'].replace([np.inf, -np.inf], 0)\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Usage_Intensity (intensidade de uso)\")\n",
        "        elif self.language_ptbr:\n",
        "            self.df['Intensidade_Uso'] = self.df['Horas_Opera√ß√£o'] / self.df['Idade_M√°quina']\n",
        "            self.df['Intensidade_Uso'] = self.df['Intensidade_Uso'].replace([np.inf, -np.inf], 0)\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Intensidade_Uso (intensidade de uso)\")\n",
        "\n",
        "        # 4. Indicador de manuten√ß√£o cr√≠tica\n",
        "        if self.language_en:\n",
        "            self.df['Critical_Maintenance'] = (\n",
        "                    self.df['Last_Maintenance_Days_Ago'] > 30\n",
        "            ).astype(int)\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Critical_Maintenance (manuten√ß√£o cr√≠tica)\")\n",
        "        elif self.language_ptbr:\n",
        "            self.df['Manuten√ß√£o_Cr√≠tica'] = (\n",
        "                    self.df['Dias_Ultima_Manuten√ß√£o'] > 30\n",
        "            ).astype(int)\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Manuten√ß√£o_Cr√≠tica (manuten√ß√£o cr√≠tica)\")\n",
        "\n",
        "        # 5. Efici√™ncia energ√©tica\n",
        "        if self.language_en:\n",
        "            self.df['Energy_Efficiency'] = self.df['Power_Consumption_kW'] / (\n",
        "                    self.df['Operational_Hours'] / 1000 + 1\n",
        "            )\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Energy_Efficiency (efici√™ncia energ√©tica)\")\n",
        "        elif self.language_ptbr:\n",
        "            self.df['Efici√™ncia_Energ√©tica'] = self.df['Consumo_Energia_kW'] / (\n",
        "                    self.df['Horas_Opera√ß√£o'] / 1000 + 1\n",
        "            )\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Efici√™ncia_Energ√©tica (efici√™ncia energ√©tica)\")\n",
        "\n",
        "        # 6. Taxa de falhas hist√≥ricas\n",
        "        if self.language_en:\n",
        "            self.df['Failure_Rate'] = self.df['Failure_History_Count'] / (\n",
        "                    self.df['Maintenance_History_Count'] + 1\n",
        "            )\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Failure_Rate (taxa de falhas hist√≥ricas)\")\n",
        "        elif self.language_ptbr:\n",
        "            self.df['Taxa_Falhas'] = self.df['Hist√≥rico_Falhas'] / (\n",
        "                    self.df['Hist√≥rico_Manuten√ß√µes'] + 1\n",
        "            )\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Taxa_Falhas (taxa de falhas hist√≥ricas)\")\n",
        "\n",
        "        # 7. Categorizar m√°quinas por idade\n",
        "        if self.language_en:\n",
        "            self.df['Age_Category'] = pd.cut(\n",
        "                self.df['Machine_Age'],\n",
        "                bins=[0, 5, 10, 15, float('inf')],\n",
        "                labels=['New', 'Young', 'Middle Age', 'Old']\n",
        "            )\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Age_Category (categoria de idade)\")\n",
        "        elif self.language_ptbr:\n",
        "            self.df['Idade_Categoria'] = pd.cut(\n",
        "                self.df['Idade_M√°quina'],\n",
        "                bins=[0, 5, 10, 15, float('inf')],\n",
        "                labels=['Nova', 'Jovem', 'Meia Idade', 'Antiga']\n",
        "            )\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Idade_Categoria (categoria de idade)\")\n",
        "\n",
        "        # 8. Identificar a D√©cada de instala√ß√£o das m√°quinas\n",
        "        if self.language_en:\n",
        "            self.df['Installation_Decade'] = (self.df['Installation_Year'] // 10 * 10).astype(str) + 's'\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: Installation_Decade (D√©cadas da instala√ß√£o identificadas no dataset)\")\n",
        "        elif self.language_ptbr:\n",
        "            self.df['D√©cada_Instala√ß√£o'] = (self.df['Ano_Instala√ß√£o'] // 10 * 10).astype(str) + 's'\n",
        "            if show_output:\n",
        "                ColoredConsole.info(\"‚úì Criado: D√©cada_Instala√ß√£o (D√©cadas da instala√ß√£o identificadas no dataset)\")\n",
        "\n",
        "        if return_df:\n",
        "          return self.df\n",
        "\n",
        "    ## 5. Sele√ß√£o de Atributos\n",
        "    def feature_selection(self, method='correlation', target_col=None, threshold=0.05):\n",
        "        \"\"\"\n",
        "        5. Sele√ß√£o de features baseada em correla√ß√£o ou import√¢ncia\n",
        "        \"\"\"\n",
        "        if target_col is None:\n",
        "            target_col = 'Failure_Within_7_Days' if self.language_en else 'Falha_Nos_Pr√≥ximos_7_Dias'\n",
        "\n",
        "        if method == 'correlation':\n",
        "            # Remover features com baixa correla√ß√£o com target\n",
        "            numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
        "            correlations = self.df[numeric_cols].corrwith(self.df[target_col]).abs()\n",
        "            low_corr_features = correlations[correlations < threshold].index.tolist()\n",
        "\n",
        "            return low_corr_features\n",
        "\n",
        "        elif method == 'variance':\n",
        "            # Remover features com baixa vari√¢ncia\n",
        "            from sklearn.feature_selection import VarianceThreshold\n",
        "            selector = VarianceThreshold(threshold=threshold)\n",
        "            numeric_data = self.df.select_dtypes(include=[np.number])\n",
        "            selector.fit(numeric_data)\n",
        "\n",
        "            low_variance_features = numeric_data.columns[~selector.get_support()].tolist()\n",
        "            return low_variance_features\n",
        "\n",
        "    ## 6. An√°lise de correla√ß√£o\n",
        "    def correlation_analysis(self, method='pearson', plot=True):\n",
        "        \"\"\"\n",
        "        6. An√°lise de correla√ß√£o com visualiza√ß√£o melhorada\n",
        "        \"\"\"\n",
        "        numeric_df = self.df.select_dtypes(include=[np.number])\n",
        "\n",
        "        if method == 'pearson':\n",
        "            corr_matrix = numeric_df.corr()\n",
        "        elif method == 'spearman':\n",
        "            corr_matrix = numeric_df.corr(method='spearman')\n",
        "        elif method == 'kendall':\n",
        "            corr_matrix = numeric_df.corr(method='kendall')\n",
        "\n",
        "        if plot:\n",
        "            plt.figure(figsize=(15, 12))\n",
        "            mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "            sns.heatmap(corr_matrix,\n",
        "                        mask=mask,\n",
        "                        annot=True,\n",
        "                        cmap='coolwarm',\n",
        "                        center=0,\n",
        "                        fmt='.2f',\n",
        "                        square=True,\n",
        "                        cbar_kws={\"shrink\": .8})\n",
        "            plt.title(f'Matriz de Correla√ß√£o ({method.title()})')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # Encontrar correla√ß√µes altas (multicolinearidade)\n",
        "        high_corr_pairs = []\n",
        "        for i in range(len(corr_matrix.columns)):\n",
        "            for j in range(i + 1, len(corr_matrix.columns)):\n",
        "                if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
        "                    high_corr_pairs.append({\n",
        "                        'var1': corr_matrix.columns[i],\n",
        "                        'var2': corr_matrix.columns[j],\n",
        "                        'correlation': corr_matrix.iloc[i, j]\n",
        "                    })\n",
        "\n",
        "        return corr_matrix, high_corr_pairs\n",
        "\n",
        "    ## 7. Encoding de Vari√°veis Categ√≥ricas (preven√ß√£o de dataleakage)\n",
        "    def encode_categorical_variables(self, encoding_type='onehot'):\n",
        "        \"\"\"\n",
        "        7. CODIFICA√á√ÉO DE VARI√ÅVEIS CATEG√ìRICAS\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"CODIFICA√á√ÉO DE VARI√ÅVEIS CATEG√ìRICAS\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        if self.language_en:\n",
        "            categorical_cols = ['Machine_Type', 'AI_Supervision', 'Age_Category', 'Machine_Functional_Category']\n",
        "        elif self.language_ptbr:\n",
        "            categorical_cols = ['Tipo_M√°quina', 'Supervis√£o_IA', 'Idade_Categoria', 'Categoria_Funcional_M√°quina']\n",
        "\n",
        "        # Remover colunas que n√£o existem no DataFrame\n",
        "        categorical_cols = [col for col in categorical_cols if col in self.df.columns]\n",
        "\n",
        "        if encoding_type == 'dummy':\n",
        "            # Dummy Encoding\n",
        "            for col in categorical_cols:\n",
        "                if col in self.df.columns:\n",
        "                    dummies = pd.get_dummies(self.df[col], prefix=col, drop_first=True)\n",
        "                    self.df = pd.concat([self.df, dummies], axis=1)\n",
        "                    self.df = self.df.drop(columns=[col])\n",
        "                    print(f\"‚úì Dummy Encoding aplicado em: {col}\")\n",
        "\n",
        "        elif encoding_type == 'onehot':\n",
        "            # One-Hot Encoding\n",
        "            try:\n",
        "                ohe_encoder = OneHotEncoder(sparse_output=False)\n",
        "            except:\n",
        "                ohe_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "            for col in categorical_cols:\n",
        "                if col in self.df.columns:\n",
        "                    onehot_data = ohe_encoder.fit_transform(self.df[[col]])\n",
        "                    try:\n",
        "                        onehot_data_df = pd.DataFrame(onehot_data, columns=ohe_encoder.get_feature_names_out([col]))\n",
        "                    except:\n",
        "                        onehot_data_df = pd.DataFrame(onehot_data, columns=ohe_encoder.get_feature_names([col]))\n",
        "                    self.df = self.df.join(onehot_data_df)\n",
        "                    self.df = self.df.drop(columns=[col])\n",
        "                    print(f\"‚úì One-Hot Encoding aplicado em: {col}\")\n",
        "\n",
        "        elif encoding_type == 'label':\n",
        "            # Label Encoding\n",
        "            for col in categorical_cols:\n",
        "                if col in self.df.columns:\n",
        "                    le = LabelEncoder()\n",
        "                    self.df[col + '_encoded'] = le.fit_transform(self.df[col])\n",
        "                    self.encoders[col] = le\n",
        "                    print(f\"‚úì Label Encoding aplicado em: {col}\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    ## 8. Feature Scaling (Normaliza√ß√£o, Padroniza√ß√£o e Normaliza√ß√£o Robust)\n",
        "    def scale_features(self, scaling_type='standard', exclude_target=True):\n",
        "        \"\"\"\n",
        "        8. NORMALIZA√á√ÉO/PADRONIZA√á√ÉO\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(f\"NORMALIZA√á√ÉO - {scaling_type.upper()}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Identificar colunas num√©ricas\n",
        "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        # Excluir vari√°veis que n√£o devem ser escalonadas\n",
        "        if self.language_en:\n",
        "            exclude_cols = ['Machine_ID', 'Installation_Year','Installation_Decade']\n",
        "            if exclude_target and 'Failure_Within_7_Days' in self.df.columns:\n",
        "                exclude_cols.append('Failure_Within_7_Days')\n",
        "        elif self.language_ptbr:\n",
        "            exclude_cols = ['ID_M√°quina', 'Ano_Instala√ß√£o','D√©cada_Instala√ß√£o']\n",
        "            if exclude_target and 'Falha_Nos_Pr√≥ximos_7_Dias' in self.df.columns:\n",
        "                exclude_cols.append('Falha_Nos_Pr√≥ximos_7_Dias')\n",
        "\n",
        "        cols_to_scale = [col for col in numeric_cols if col not in exclude_cols]\n",
        "\n",
        "        if scaling_type == 'standard':\n",
        "            scaler = StandardScaler()\n",
        "        elif scaling_type == 'minmax':\n",
        "            scaler = MinMaxScaler()\n",
        "        elif scaling_type == 'robust':\n",
        "            scaler = RobustScaler()\n",
        "\n",
        "        # Aplicar escalonamento apenas nas colunas selecionadas\n",
        "        if cols_to_scale:\n",
        "            self.df[cols_to_scale] = scaler.fit_transform(self.df[cols_to_scale])\n",
        "\n",
        "        self.scalers[scaling_type] = scaler\n",
        "        print(f\"‚úì {scaling_type.title()} Scaling aplicado em {len(cols_to_scale)} vari√°veis\")\n",
        "        print(f\"  Colunas preservadas: {', '.join(exclude_cols)}\")\n",
        "\n",
        "        return self.df\n",
        "\n",
        "    ## 9. Vers√µes Pr√©-Processadas em DataFrames\n",
        "    def create_processed_versions(self):\n",
        "        \"\"\"\n",
        "        9. CRIAR DIFERENTES VERS√ïES PROCESSADAS\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"CRIANDO VERS√ïES PROCESSADAS DO DATASET\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        versions = {}\n",
        "\n",
        "        # Vers√£o 1: Apenas limpeza b√°sica\n",
        "        df_basic = self.original_df.copy()\n",
        "        preprocessor_basic = IoTDataPreprocessor(df_basic, language_en=self.language_en, language_ptbr=self.language_ptbr)\n",
        "        preprocessor_basic.handle_missing_values(show_output=False)\n",
        "        versions['basic_cleaned'] = preprocessor_basic.df\n",
        "        print(\"‚úì Vers√£o 1: Limpeza b√°sica\")\n",
        "\n",
        "        # Vers√£o 2: Com engenharia de features\n",
        "        df_engineered = self.original_df.copy()\n",
        "        preprocessor_eng = IoTDataPreprocessor(df_engineered, language_en=self.language_en, language_ptbr=self.language_ptbr)\n",
        "        preprocessor_eng.handle_missing_values(show_output=False)\n",
        "        preprocessor_eng.feature_engineering()\n",
        "        versions['feature_engineered'] = preprocessor_eng.df\n",
        "        print(\"‚úì Vers√£o 2: Com engenharia de features\")\n",
        "\n",
        "        # Vers√£o 3: Normalizada (Standard)\n",
        "        df_standard = self.original_df.copy()  # Come√ßar do original\n",
        "        preprocessor_std = IoTDataPreprocessor(df_standard, language_en=self.language_en, language_ptbr=self.language_ptbr)\n",
        "        preprocessor_std.handle_missing_values(show_output=False)\n",
        "        preprocessor_std.feature_engineering(show_output=False)\n",
        "        preprocessor_std.encode_categorical_variables('onehot')\n",
        "        preprocessor_std.scale_features('standard')\n",
        "        versions['standard_scaled'] = preprocessor_std.df\n",
        "        print(\"‚úì Vers√£o 3: Padronizada (Standard Scaler)\")\n",
        "\n",
        "        # Vers√£o 4: Normalizada (MinMax)\n",
        "        df_minmax = self.original_df.copy()  # Come√ßar do original\n",
        "        preprocessor_mm = IoTDataPreprocessor(df_minmax, language_en=self.language_en, language_ptbr=self.language_ptbr)\n",
        "        preprocessor_mm.handle_missing_values(show_output=False)\n",
        "        preprocessor_mm.feature_engineering(show_output=False)\n",
        "        preprocessor_mm.encode_categorical_variables('onehot')\n",
        "        preprocessor_mm.scale_features('minmax')\n",
        "        versions['minmax_scaled'] = preprocessor_mm.df\n",
        "        print(\"‚úì Vers√£o 4: Normalizada (MinMax Scaler)\")\n",
        "\n",
        "        # Vers√£o 5: Robusta (Robust Scaler)\n",
        "        df_robust = self.original_df.copy()  # Come√ßar do original\n",
        "        preprocessor_rob = IoTDataPreprocessor(df_robust, language_en=self.language_en, language_ptbr=self.language_ptbr)\n",
        "        preprocessor_rob.handle_missing_values(show_output=False)\n",
        "        preprocessor_rob.feature_engineering(show_output=False)\n",
        "        preprocessor_rob.encode_categorical_variables('onehot')\n",
        "        preprocessor_rob.scale_features('robust')\n",
        "        versions['robust_scaled'] = preprocessor_rob.df\n",
        "        print(\"‚úì Vers√£o 5: Robusta (Robust Scaler)\")\n",
        "\n",
        "        # Verificar se a coluna target est√° presente em todas as vers√µes\n",
        "        print(\"\\nVerificando presen√ßa da coluna target:\")\n",
        "        for version_name, df_version in versions.items():\n",
        "            target_variable = ''\n",
        "            if self.language_en:\n",
        "                target_variable = 'Failure_Within_7_Days'\n",
        "            elif self.language_ptbr:\n",
        "                target_variable = 'Falha_Nos_Pr√≥ximos_7_Dias'\n",
        "\n",
        "            if target_variable in df_version.columns:\n",
        "                print(f\"  ‚úì {version_name}: Coluna target \\\"{target_variable}\\\" presente!\")\n",
        "            else:\n",
        "                print(f\"  ‚úó {version_name}: AVISO - Coluna target \\\"{target_variable}\\\" ausente!\")\n",
        "\n",
        "        return versions\n",
        "\n",
        "    ## 10. Comparar distribui√ß√µes entre bases distintas j√° pr√©processadas\n",
        "    def compare_distributions(self, versions_dict):\n",
        "        \"\"\"\n",
        "        10. COMPARAR DISTRIBUI√á√ïES ANTES E DEPOIS\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"AN√ÅLISE COMPARATIVA DAS TRANSFORMA√á√ïES\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Selecionar algumas vari√°veis chave para compara√ß√£o\n",
        "        if self.language_en:\n",
        "            key_vars = ['Temperature_C', 'Vibration_mms', 'Power_Consumption_kW', 'Operational_Hours']\n",
        "        elif self.language_ptbr:\n",
        "            key_vars = ['Temperatura_Celsius', 'Vibra√ß√£o_mms', 'Consumo_Energia_kW', 'Horas_Opera√ß√£o']\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        axes = axes.ravel()\n",
        "\n",
        "        for i, var in enumerate(key_vars):\n",
        "            if var in self.original_df.columns:\n",
        "                # Dados originais\n",
        "                axes[i].hist(self.original_df[var], bins=30, alpha=0.5,\n",
        "                             label='Original', color='blue')\n",
        "\n",
        "                # Dados processados (vers√£o standard)\n",
        "                if var in versions_dict['standard_scaled'].columns:\n",
        "                    axes[i].hist(versions_dict['standard_scaled'][var], bins=30,\n",
        "                                 alpha=0.5, label='Padronizado', color='red')\n",
        "\n",
        "                axes[i].set_title(f'Distribui√ß√£o: {var}')\n",
        "                axes[i].legend()\n",
        "                axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Estat√≠sticas comparativas\n",
        "        print(\"\\nEstat√≠sticas comparativas (Original vs Padronizado):\")\n",
        "        for var in key_vars:\n",
        "            if var in self.original_df.columns and var in versions_dict['standard_scaled'].columns:\n",
        "                orig_mean = self.original_df[var].mean()\n",
        "                orig_std = self.original_df[var].std()\n",
        "                proc_mean = versions_dict['standard_scaled'][var].mean()\n",
        "                proc_std = versions_dict['standard_scaled'][var].std()\n",
        "\n",
        "                print(f\"\\n{var}:\")\n",
        "                print(f\"  Original: Œº={orig_mean:.2f}, œÉ={orig_std:.2f}\")\n",
        "                print(f\"  Padronizado: Œº={proc_mean:.2f}, œÉ={proc_std:.2f}\")"
      ],
      "metadata": {
        "id": "sFQ7U5hw4WTN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fun√ß√£o para exibir as caracter√≠sticas b√°sicas iniciais do dataset em mardown utilizando Ipython\n",
        "def display_dataset_characteristics(df, language='en'):\n",
        "    \"\"\"\n",
        "    Exibe as caracter√≠sticas b√°sicas do dataset IoT Industrial usando IPython display e Markdown.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas.DataFrame\n",
        "        Dataset IoT Industrial para an√°lise\n",
        "    language : str, default 'en'\n",
        "        Idioma para exibi√ß√£o ('en' para ingl√™s, 'pt' para portugu√™s)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    None\n",
        "        Fun√ß√£o apenas exibe informa√ß√µes, n√£o retorna valores\n",
        "    \"\"\"\n",
        "\n",
        "    if language == 'ptbr':\n",
        "        # Vers√£o em Portugu√™s\n",
        "        markdown_content = \"\"\"\n",
        "# Caracter√≠sticas do Dataset IoT Industrial\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ùó Objetivo do Dataset\n",
        "Este dataset √© t√≠pico para **manuten√ß√£o preditiva**, onde o objetivo √© prever falhas antes que aconte√ßam, usando dados de sensores IoT para otimizar a manuten√ß√£o industrial.\n",
        "\n",
        "* ‚ö†Ô∏è Aten√ß√£o: Todos os dados s√£o totalmente **sint√©ticos**, criados para imitar tend√™ncias industriais realistas para explora√ß√£o e modelagem seguras. **N√£o foram utilizados dados do mundo real.**\n",
        "<BR>\n",
        "<BR>\n",
        "\n",
        "---\n",
        "\n",
        "## üè≠ Categoriza√ß√£o de M√°quinas\n",
        "\n",
        "* ‚ö†Ô∏è Aten√ß√£o: Esta vari√°vel n√£o √© original do dataset, com base em similaridades de fun√ß√µes foram criadas categorias para as m√°quinas. Esta √© uma das a√ß√µes de **Engenharia de Atributos**, onde criamos novas informa√ß√µes baseadas nas existentes.\n",
        "<BR>\n",
        "<BR>\n",
        "\n",
        "A vari√°vel \"**Tipo_M√°quina**\" possui a informa√ß√£o de quais classes os maquin√°rios s√£o categorizados.\n",
        "\n",
        "O dataset inclui conhecimento espec√≠fico do dom√≠nio com **32 tipos de m√°quinas** categorizadas em 6 grupos funcionais:\n",
        "\n",
        "* **Fabrica√ß√£o e Conforma√ß√£o**: M√°quina de Corte a Laser, Torno CNC, Forno Industrial, Prensa Hidr√°ulica, Dobradeira/Quinadora, Impressora 3D, Retificadora/Moedor, Fresadora CNC, Injetora de Pl√°stico\n",
        "\n",
        "* **Processamento e Montagem**: Misturador, M√°quina de Pegar e Colocar, Parafusadeira Automatizada, Bra√ßo Rob√≥tico\n",
        "\n",
        "* **Manuseio e Log√≠stica**: Sistema de Shuttle, Ve√≠culo Guiado Automatizado, Correia Transportadora/Esteira, Empilhadeira El√©trica, Ponte Rolante/Guindaste\n",
        "\n",
        "* **Inspe√ß√£o e Qualidade**: Sistema de Vis√£o, M√°quina de Medi√ß√£o por Coordenadas, Inspetor de Raios-X\n",
        "\n",
        "* **Embalagem e Finaliza√ß√£o**: Rotuladora, Embaladora Termoencolh√≠vel, Secador Industrial, Armadora de Caixas, Embaladora a V√°cuo, Paletizador\n",
        "\n",
        "* **Suporte e Utilit√°rios**: Chiller Industrial, Controlador de V√°lvula, Compressor, Caldeira, Trocador de Calor, Bomba\n",
        "<BR>\n",
        "<BR>\n",
        "\n",
        "## üìã Informa√ß√µes Detalhadas dos Atributos\n",
        "\n",
        "### üîß Identifica√ß√£o e Caracter√≠sticas da M√°quina\n",
        "* **ID_M√°quina**: Identificador √∫nico de cada m√°quina no sistema\n",
        "\n",
        "* **Tipo_M√°quina**: Categoria ou modelo da m√°quina (ex: torno, fresadora, prensa)\n",
        "\n",
        "* **Ano_Instala√ß√£o**: Ano em que a m√°quina foi instalada na f√°brica\n",
        "\n",
        "* **Horas_Opera√ß√£o**: Total de horas que a m√°quina j√° operou desde a instala√ß√£o\n",
        "\n",
        "### üì° Sensores de Monitoramento\n",
        "* **Temperatura_Celsius**: Temperatura atual da m√°quina em graus Celsius\n",
        "\n",
        "* **Vibra√ß√£o_mms**: N√≠vel de vibra√ß√£o medido em mil√≠metros por segundo (indicador de desgaste)\n",
        "\n",
        "* **Ru√≠do_dB**: N√≠vel de ru√≠do produzido pela m√°quina em decib√©is\n",
        "\n",
        "* **N√≠vel_√ìleo_%**: Percentual do n√≠vel de √≥leo lubrificante no reservat√≥rio\n",
        "\n",
        "* **Fluido_Refrigerante_%**: Percentual do n√≠vel de l√≠quido refrigerante\n",
        "\n",
        "* **Consumo_Energia_kW**: Consumo atual de energia el√©trica em quilowatts\n",
        "\n",
        "### üå°Ô∏è Sensores Espec√≠ficos\n",
        "* **Intensidade_Laser**: Intensidade do laser (para m√°quinas que usam corte/soldagem a laser)\n",
        "\n",
        "* **Press√£o_Hidr√°ulica_bar**: Press√£o do sistema hidr√°ulico em bar\n",
        "\n",
        "* **Fluxo_Fluido_Refrigerante_L_min**: Taxa de fluxo do l√≠quido refrigerante em litros por minuto\n",
        "\n",
        "* **√çndice_Calor**: √çndice calculado que representa o n√≠vel geral de aquecimento da m√°quina\n",
        "\n",
        "### üîß Hist√≥rico de Manuten√ß√£o\n",
        "* **Dias_Ultima_Manuten√ß√£o**: N√∫mero de dias desde a √∫ltima manuten√ß√£o realizada\n",
        "\n",
        "* **Hist√≥rico_Manuten√ß√µes**: Quantidade total de manuten√ß√µes j√° realizadas na m√°quina\n",
        "\n",
        "* **Hist√≥rico_Falhas**: N√∫mero de falhas registradas no hist√≥rico da m√°quina\n",
        "\n",
        "### ü§ñ Sistema de IA e Monitoramento\n",
        "* **Supervis√£o_IA**: Indica se a m√°quina est√° sob supervis√£o de sistema de IA (True/False)\n",
        "\n",
        "* **C√≥digos_Erros_30_Dias**: Quantidade de c√≥digos de erro registrados nos √∫ltimos 30 dias\n",
        "\n",
        "* **Eventos_Sobrescrita_IA**: N√∫mero de vezes que operadores humanos sobrescreveram decis√µes da IA\n",
        "\n",
        "### üéØ Predi√ß√£o e An√°lise\n",
        "* **Vida_√ötil_Restante_Dias** üìâüìÖ: Estimativa de quantos dias a m√°quina ainda pode operar antes de precisar de manuten√ß√£o\n",
        "\n",
        "* **Falha_Nos_Pr√≥ximos_7_Dias** üéØüìÖ - **Vari√°vel target**: Indica se a m√°quina falhar√° nos pr√≥ximos 7 dias (True/False)\n",
        "\"\"\"\n",
        "\n",
        "    else:\n",
        "        # Vers√£o em Ingl√™s\n",
        "        markdown_content = \"\"\"\n",
        "# IoT Industrial Dataset Characteristics\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ùó Dataset Objective\n",
        "This dataset is typical for **predictive maintenance**, where the goal is to predict failures before they happen, using IoT sensor data to optimize industrial maintenance.\n",
        "\n",
        "* ‚ö†Ô∏è Attention: All data is fully **synthetic**, created to mimic realistic industrial trends for safe exploration and modeling. No real-world data was used.\n",
        "<BR>\n",
        "<BR>\n",
        "\n",
        "---\n",
        "\n",
        "## üè≠ Machine Categorization\n",
        "\n",
        "* ‚ö†Ô∏è Attention: This variable is not original to the dataset, based on similarities in functions, categories were created for the machines. This is one of the **Attribute Engineering** actions, where we create new information based on existing information.\n",
        "<BR>\n",
        "<BR>\n",
        "\n",
        "The \"**Machine_Type**\" variable contains information about how machinery is categorized.\n",
        "\n",
        "The dataset includes domain-specific knowledge with **32 machine types** categorized into 6 functional groups:\n",
        "\n",
        "* **Manufacturing and Forming**: Laser_Cutter, CNC_Lathe, Furnace, Hydraulic_Press, Press_Brake, 3D_Printer, Grinder, CNC_Mill, Injection_Molder\n",
        "\n",
        "* **Processing and Assembly**: Mixer, Pick_and_Place, Automated_Screwdriver, Robot_Arm\n",
        "\n",
        "* **Material Handling and Logistics**: Shuttle_System, AGV, Conveyor_Belt, Forklift_Electric, Crane\n",
        "\n",
        "* **Inspection and Quality Control**: Vision_System, CMM, XRay_Inspector\n",
        "\n",
        "* **Packaging and Finishing**: Labeler, Shrink_Wrapper, Dryer, Carton_Former, Vacuum_Packer, Palletizer\n",
        "\n",
        "* **Support and Utilities**: Industrial_Chiller, Valve_Controller, Compressor, Boiler, Heat_Exchanger, Pump\n",
        "The \"**Machine_Type**\" variable contains information about how machinery is categorized.\n",
        "<BR>\n",
        "<BR>\n",
        "\n",
        "## üìã Detailed Attribute Information\n",
        "\n",
        "### üîß Machine Identification and Characteristics\n",
        "* **Machine_ID**: Unique identifier for each machine in the system\n",
        "\n",
        "* **Machine_Type**: Category or model of the machine (e.g., lathe, mill, press)\n",
        "\n",
        "* **Installation_Year**: Year the machine was installed in the factory\n",
        "\n",
        "* **Operational_Hours**: Total hours the machine has operated since installation\n",
        "\n",
        "### üì° Monitoring Sensors\n",
        "* **Temperature_C**: Current machine temperature in degrees Celsius\n",
        "\n",
        "* **Vibration_mms**: Vibration level measured in millimeters per second (wear indicator)\n",
        "\n",
        "* **Sound_dB**: Noise level produced by the machine in decibels\n",
        "\n",
        "* **Oil_Level_pct**: Percentage of lubricating oil level in the reservoir\n",
        "\n",
        "* **Coolant_Level_pct**: Percentage of coolant fluid level\n",
        "\n",
        "* **Power_Consumption_kW**: Current electrical energy consumption in kilowatts\n",
        "\n",
        "### üå°Ô∏è Specific Sensors\n",
        "* **Laser_Intensity**: Laser intensity (for machines using laser cutting/welding)\n",
        "\n",
        "* **Hydraulic_Pressure_bar**: Hydraulic system pressure in bar\n",
        "\n",
        "* **Coolant_Flow_L_min**: Coolant flow rate in liters per minute\n",
        "\n",
        "* **Heat_Index**: Calculated index representing the machine's overall heating level\n",
        "\n",
        "### üîß Maintenance History\n",
        "* **Last_Maintenance_Days_Ago**: Number of days since the last maintenance was performed\n",
        "\n",
        "* **Maintenance_History_Count**: Total number of maintenances already performed on the machine\n",
        "\n",
        "* **Failure_History_Count**: Number of failures recorded in the machine's history\n",
        "\n",
        "### ü§ñ AI System and Monitoring\n",
        "* **AI_Supervision**: Indicates if the machine is under AI system supervision (True/False)\n",
        "\n",
        "* **Error_Codes_Last_30_Days**: Number of error codes recorded in the last 30 days\n",
        "\n",
        "* **AI_Override_Events**: Number of times human operators overrode AI decisions\n",
        "\n",
        "### üéØ Prediction and Analysis\n",
        "* **Remaining_Useful_Life_days** üìâüìÖ: Estimate of how many days the machine can still operate before needing maintenance\n",
        "\n",
        "* **Failure_Within_7_Days** üéØüìÖ: Indicates if the machine will fail in the next 7 days (True/False)\n",
        "\"\"\"\n",
        "\n",
        "    # Exibir o conte√∫do Markdown\n",
        "    display(Markdown(markdown_content))"
      ],
      "metadata": {
        "id": "kYiS81blYfE4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Realiza a carga do dataset** üóí\n",
        "\n",
        "Carrega o arquivo utilizando a api KaggleHub;\n",
        "\n",
        "Origem do dataset: [https://www.kaggle.com/datasets/canozensoy/industrial-iot-dataset-synthetic](https://www.kaggle.com/datasets/canozensoy/industrial-iot-dataset-synthetic)\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://storage.googleapis.com/kaggle-datasets-images/7310492/11649422/dbdbaeaee648d7901a43a9e1981f1e09/dataset-cover.png?t=2025-05-02-12-31-54\" width=\"55%\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "DzMHXSrTtXMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Realiza a carga do dataset\n",
        "\n",
        "try:\n",
        "    ColoredConsole.show_section_header(\"Realizando Carga do Dataset atrav√©s da api KaggleHub\\n(Kaggle: \\\"canozensoy/industrial-iot-dataset-synthetic\\\"))\")\n",
        "\n",
        "    df_iot = kagglehub.dataset_load(\n",
        "        KaggleDatasetAdapter.PANDAS,\n",
        "        \"canozensoy/industrial-iot-dataset-synthetic\",\n",
        "        \"factory_sensor_simulator_2040.csv\",\n",
        "    )\n",
        "    if not df_iot.empty:\n",
        "        ColoredConsole.success(\"Carga realizada com sucesso!\".center(60))\n",
        "        ColoredConsole.print_colored((\"!\"*60).center(60), 'white', 'bg_green', 'bold')\n",
        "except:\n",
        "    ColoredConsole.print_colored((\"x\"*60).center(60), 'white', 'bg_red', 'bold')\n",
        "    ColoredConsole.show_section_header(\"N√£o foi poss√≠vel carregar atrav√©s da api KaggleHub;\\nCarga ser√° realizada atrav√©s do arquivo raw csv via github!\")\n",
        "\n",
        "    df_iot = pd.read_csv('https://raw.githubusercontent.com/vinileodido/MVP_PucRio_AnaliseDados/refs/heads/main/data/factory_sensor_simulator_2040.csv')\n",
        "    if not df_iot.empty:\n",
        "        ColoredConsole.success(\"Carga realizada com sucesso!\".center(60))\n",
        "        ColoredConsole.print_colored((\"!\"*60).center(60), 'white', 'bg_green', 'bold')"
      ],
      "metadata": {
        "id": "7jYTuW8z4YLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# An√°lise de dados e informa√ß√µes sobre o dataset\n"
      ],
      "metadata": {
        "id": "qiteuk6mwKxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibindo informa√ß√µes b√°sicas dos atributos do dataset\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\n",
        "\n",
        "display_dataset_characteristics(df_iot, language='ptbr')\n",
        "\n",
        "# altere o par√¢metro \"language='en'\"\" - para visualizar informa√ß√µes em ingl√™s"
      ],
      "metadata": {
        "id": "MBRGp44-U3YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descri√ß√£o do Problema"
      ],
      "metadata": {
        "id": "t5Hwjv_ysfYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5500})'''))\n",
        "\n",
        "print('='*80)\n",
        "ColoredConsole.print_colored(\"INICIANDO PIPELINE DE PR√â-PROCESSAMENTO\".center(80), 'cyan', None, 'bold')\n",
        "print('='*80)\n",
        "\n",
        "# Inicializar preprocessador, selecionando apresenta√ß√£o do dataset em Portugu√™s\n",
        "preprocessor = IoTDataPreprocessor(df_iot, language_en=False, language_ptbr=True)\n",
        "\n",
        "# 1. An√°lise inicial dos dados do dataset\n",
        "preprocessor.analyze_data_quality()"
      ],
      "metadata": {
        "id": "sE547LSK4bLb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento de Valores Faltantes (Missing)"
      ],
      "metadata": {
        "id": "pwQ-TyM8DdvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\n",
        "\n",
        "# 2. Tratar valores missing\n",
        "preprocessor.handle_missing_values(strategy='zero',return_df=False)"
      ],
      "metadata": {
        "id": "fDAliP7SFiRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\n",
        "\n",
        "# --- Cria√ß√£o do Painel de Histogramas ---\n",
        "\n",
        "# 1. Identificar as variaveis numericas de sensores\n",
        "sensor_columns = preprocessor.df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Vamos remover colunas que podem ser identificadores e n√£o sensores\n",
        "if preprocessor.language_en:\n",
        "  ids_to_exclude = ['Machine_ID']\n",
        "elif preprocessor.language_ptbr:\n",
        "  ids_to_exclude = ['ID_M√°quina']\n",
        "\n",
        "sensor_columns = [col for col in sensor_columns if col not in ids_to_exclude]\n",
        "\n",
        "\n",
        "# 2. Definir o layout da grade de subplots\n",
        "n_cols = 3  # For√ßar exibi√ß√£o de 3 gr√°ficos por linha\n",
        "n_rows = (len(sensor_columns) - 1) // n_cols + 1 # Calcula o n√∫mero de linhas necess√°rias\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))\n",
        "axes = axes.flatten() # transforma a grade 2D em uma lista 1D para performar o loop\n",
        "\n",
        "\n",
        "# 3. Popular cada subplot com um histograma\n",
        "for i, col_name in enumerate(sensor_columns):\n",
        "    ax = axes[i]\n",
        "    sns.histplot(data=preprocessor.df, x=col_name, kde=True, ax=ax, color='teal', bins=40)\n",
        "    ax.set_title(f'Distribui√ß√£o de {col_name}', fontsize=12)\n",
        "    ax.set_xlabel('') # Opcional: remover o label x para um visual mais limpo\n",
        "    ax.set_ylabel('Frequ√™ncia')\n",
        "\n",
        "# 4. Remover eixos vazios (caso o n√∫mero de gr√°ficos n√£o preencha a grade perfeitamente)\n",
        "for i in range(len(sensor_columns), len(axes)):\n",
        "    axes[i].set_visible(False)\n",
        "\n",
        "# Ajusta o layout para evitar sobreposi√ß√£o de t√≠tulos e eixos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Exibe o painel de gr√°ficos\n",
        "display(plt.show())"
      ],
      "metadata": {
        "id": "geFor8HVRoLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Engenharia de features\n",
        "preprocessor.feature_engineering(return_df=False)"
      ],
      "metadata": {
        "id": "admVT97ZFkZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\n",
        "\n",
        "# --- Cria√ß√£o do Painel de Histogramas ---\n",
        "\n",
        "# 1. Identificar as variaveis numericas de sensores\n",
        "sensor_columns = preprocessor.df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Vamos remover colunas que podem ser identificadores e n√£o sensores\n",
        "if preprocessor.language_en:\n",
        "  ids_to_exclude = ['Machine_ID']\n",
        "  param_hue = 'Machine_Functional_Category'\n",
        "elif preprocessor.language_ptbr:\n",
        "  ids_to_exclude = ['ID_M√°quina']\n",
        "  param_hue = 'Categoria_Funcional_M√°quina'\n",
        "\n",
        "sensor_columns = [col for col in sensor_columns if col not in ids_to_exclude]\n",
        "\n",
        "\n",
        "# 2. Definir o layout da grade de subplots\n",
        "n_cols = 3  # For√ßar exibi√ß√£o de 3 gr√°ficos por linha\n",
        "n_rows = (len(sensor_columns) - 1) // n_cols + 1 # Calcula o n√∫mero de linhas necess√°rias\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))\n",
        "axes = axes.flatten() # transforma a grade 2D em uma lista 1D para performar o loop\n",
        "\n",
        "\n",
        "# 3. Popular cada subplot com um histograma\n",
        "for i, col_name in enumerate(sensor_columns):\n",
        "    ax = axes[i]\n",
        "    sns.histplot(data=preprocessor.df, x=col_name, kde=True, ax=ax, bins=40, hue=param_hue, palette='YlGnBu')\n",
        "    ax.set_title(f'Distribui√ß√£o de {col_name}', fontsize=12)\n",
        "    ax.set_xlabel('') # Opcional: remover o label x para um visual mais limpo\n",
        "    ax.set_ylabel('Frequ√™ncia')\n",
        "\n",
        "# 4. Remover eixos vazios (caso o n√∫mero de gr√°ficos n√£o preencha a grade perfeitamente)\n",
        "for i in range(len(sensor_columns), len(axes)):\n",
        "    axes[i].set_visible(False)\n",
        "\n",
        "# Ajusta o layout para evitar sobreposi√ß√£o de t√≠tulos e eixos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Exibe o painel de gr√°ficos\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gNA46JXrY9zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\n",
        "\n",
        "# Focar nos tipos de m√°quina mais comuns\n",
        "# Selecionar apenas os 8 tipos mais frequentes de m√°quina\n",
        "top_machine_types = preprocessor.df['Tipo_M√°quina'].value_counts().head(8).index.tolist()\n",
        "df_filtered = preprocessor.df[preprocessor.df['Tipo_M√°quina'].isin(top_machine_types)].copy()\n",
        "\n",
        "print(f\"Tipos de m√°quina mais comuns (top 8):\")\n",
        "print(preprocessor.df['Tipo_M√°quina'].value_counts().head(8))\n",
        "print('\\n\\n')\n",
        "\n",
        "# Boxplots por Tipo de M√°quina - Top 8\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "fig.suptitle('Boxplots por Tipo de M√°quina (Top 8 Tipos Mais Comuns)', fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "key_vars = ['Temperatura_Celsius', 'Vibra√ß√£o_mms', 'Consumo_Energia_kW',\n",
        "           '√çndice_Degrada√ß√£o', 'Efici√™ncia_Energ√©tica', 'Taxa_Falhas']\n",
        "\n",
        "for i, var in enumerate(key_vars):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "\n",
        "    if var in preprocessor.df.columns:\n",
        "        sns.boxplot(data=df_filtered, x='Tipo_M√°quina', y=var, ax=axes[row, col])\n",
        "        axes[row, col].set_title(f'{var}', fontweight='bold', fontsize=12)\n",
        "        axes[row, col].tick_params(axis='x', rotation=45, labelsize=10)\n",
        "        axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "        # Melhorar formata√ß√£o dos labels\n",
        "        axes[row, col].set_xlabel('Tipo de M√°quina', fontsize=10)\n",
        "        axes[row, col].set_ylabel(var.replace('_', ' '), fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "iBckXFlmjey2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trata os outliers atrav√©s do m√©todo de dist√¢ncia interquartil (IQR)\n",
        "---\n",
        "\n",
        "### M√©todo de Dist√¢ncia Interquartil (IQR)\n",
        "    \n",
        "T√©cnica estat√≠stica para identifica√ß√£o de outliers baseada nos quartis dos dados.\n",
        "    \n",
        "\n",
        "**Defini√ß√µes:**\n",
        "- $Q_1 = \\text{Primeiro quartil (25¬∫ percentil)}$\n",
        "- $Q_3 = \\text{Terceiro quartil (75¬∫ percentil)}$\n",
        "\n",
        "**C√°lculos:**\n",
        "- $IQR = Q_3 - Q_1$\n",
        "- $L_{inf} = Q_1 - 1{,}5 \\times IQR$\n",
        "- $L_{sup} = Q_3 + 1{,}5 \\times IQR$\n",
        "\n",
        "**Crit√©rio:**\n",
        "Um valor $x_i$ √© outlier se: $x_i < L_{inf}$ ou $x_i > L_{sup}$\n",
        "\n",
        "---\n",
        "<BR>\n",
        "\n",
        "```python\n",
        "#utiliza o mesmo dataframe _self.df que estamos utilizando atrav√©s da inst√¢ncia da classe\n",
        "detected_outliers = preprocessor.detect_outliers(method='IQR', threshold=1.5)\n",
        "\n",
        "preprocessor.handle_outliers(method='cap', outliers=detected_outliers)\n",
        "```\n",
        "\n",
        "Utilizando a estrat√©gia de **Capping/Winsorization**, limitando valores extremos aos percentis 5% e 95% e preservando em parte o tamanho do dataset.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "r9jmqOPCdHZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\n",
        "\n",
        "#Identifica quem s√£o os outliers atrav√©s de IQR\n",
        "detected_outliers = preprocessor.detect_outliers(method='iqr', threshold=20)\n",
        "\n",
        "#Trata os outliers atrav√©s de Capping/Winsorization\n",
        "preprocessor.handle_outliers(method='cap', outlier_info=detected_outliers)\n",
        "\n",
        "#Valida tratamento de outliers realizado\n",
        "preprocessor.validate_outlier_treatment(original_outlier_info=detected_outliers)\n"
      ],
      "metadata": {
        "id": "lW_JzqqHpKQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))\n",
        "\n",
        "# Focar nos tipos de m√°quina mais comuns\n",
        "# Selecionar apenas os 8 tipos mais frequentes de m√°quina\n",
        "top_machine_types = preprocessor.df['Tipo_M√°quina'].value_counts().head(8).index.tolist()\n",
        "df_filtered = preprocessor.df[preprocessor.df['Tipo_M√°quina'].isin(top_machine_types)].copy()\n",
        "\n",
        "print(f\"Tipos de m√°quina mais comuns (top 8):\")\n",
        "print(preprocessor.df['Tipo_M√°quina'].value_counts().head(8))\n",
        "print('\\n\\n')\n",
        "\n",
        "# Boxplots por Tipo de M√°quina - Top 8\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
        "fig.suptitle('Boxplots por Tipo de M√°quina (Top 8 Tipos Mais Comuns)', fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "key_vars = ['Temperatura_Celsius', 'Vibra√ß√£o_mms', 'Consumo_Energia_kW',\n",
        "           '√çndice_Degrada√ß√£o', 'Efici√™ncia_Energ√©tica', 'Taxa_Falhas']\n",
        "\n",
        "for i, var in enumerate(key_vars):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "\n",
        "    if var in preprocessor.df.columns:\n",
        "        sns.boxplot(data=df_filtered, x='Tipo_M√°quina', y=var, ax=axes[row, col])\n",
        "        axes[row, col].set_title(f'{var}', fontweight='bold', fontsize=12)\n",
        "        axes[row, col].tick_params(axis='x', rotation=45, labelsize=10)\n",
        "        axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "        # Melhorar formata√ß√£o dos labels\n",
        "        axes[row, col].set_xlabel('Tipo de M√°quina', fontsize=10)\n",
        "        axes[row, col].set_ylabel(var.replace('_', ' '), fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0LIKLYj2pPo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}